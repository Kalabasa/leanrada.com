<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title><![CDATA[leanrada.com Notes]]></title>
        <description><![CDATA[leanrada.com Notes]]></description>
        <link>https://leanrada.com</link>
        <generator>RSS for Node</generator>
        
        <atom:link href="https://leanrada.com/rss.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Pure CSS volley ball game]]></title>
            <description><![CDATA[<p>I don‚Äôt know why I did this, but it was fun / funny.</p><p>This is a volley ball / tennis game implemented purely using HTML and CSS. Features real-time action gameplay and score counting.</p><p>üëâ See the Pen <a target="_blank" href="https://codepen.io/kalabasa/pen/MWzmPXb">Pure CSS Volley Game</a> on CodePen!</p><video muted="" autoplay="" loop="" aria-label="video of CSS volley ball video game">
                                <source src="https://leanrada.com/notes/pure-css-volley-ball-game/video.mp4">
                                <a href="https://leanrada.com/notes/pure-css-volley-ball-game/video.mp4">video of CSS volley ball video game</a>
                            </video>]]></description>
            <link>https://leanrada.com/notes/pure-css-volley-ball-game</link>
            <guid isPermaLink="true">https://leanrada.com/notes/pure-css-volley-ball-game</guid>
            <pubDate>Sun, 02 Jul 2023 14:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Dynamic patrol behaviour in stealth games with Markov chains]]></title>
            <description><![CDATA[<p>Hi, this post is about a game AI algorithm for stealth games.</p><p>But first, here‚Äôs a preview demo! Full demo at the end of this post. In between, I‚Äôll explain the background, the process, and the results!</p><p></p><pre>Interactive content: <a href="https://leanrada.com/notes/dynamic-patrol-stealth-games">See it on leanrada.com.</a>
Alternative text: </pre><p>I enjoy stealth games. However, I felt like the genre has become formulaic. Nowadays, we have standardised light, shadow, and noise mechanics. We almost always get discrete levels of alertness where on one end NPCs have wallhacks while on the other, NPCs have amnesia.</p><img srcset="" sizes="" alt="Screenshot of Splinter Cell" src="https://leanrada.com/notes/dynamic-patrol-stealth-games/sc.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><p>The most immersion-breaking moment for me was when you get spotted, the subsequent investigation consists solely of staring at the ground where you were last seen. Like when you get spotted at an entrance to a room, guards will just stare at the doorway. <em>Why not check inside the room?</em></p><p><span>Yeah, I know, game designers don't deem smart game AI ‚Äúfun‚Äù. But an easy predictable game is no fun! Whatever, I just wanted to share this prototype.</span></p><p>What was lacking in stealth game AI is inference - the ability to infer that when a target enters a room, then they subsequently must be inside the room.</p><p>As an example, here are a room and a hallway with a doorway in between, modelled as a <a target="_blank" href="https://en.wikipedia.org/wiki/Graph">graph</a>:</p><img srcset="" sizes="" alt="Node graph representing a room node, a doorway node, and hallway nodes" src="https://leanrada.com/notes/dynamic-patrol-stealth-games/room-graph.png" spec="300" loading="lazy" width="" height=""><p>If we assign a number to each node representing the probability that the target (the player) is there, we can start making inferences of where the target could be at later times.</p><p>Let‚Äôs say the target was just seen in room <em>R</em>. At that exact moment, there is complete certainty that the target is there, so node <em>R</em> will be assigned a probability of <strong>1.0</strong>.</p><img srcset="" sizes="" alt="Node graph representing the room node with 1.0, the doorway node with 0.0, and hallway nodes with 0.0" src="https://leanrada.com/notes/dynamic-patrol-stealth-games/room-graph-r1.png" spec="300" loading="lazy" width="" height=""><p>After that moment however, the certainty fades. Because the target could have exited the room next, or maybe they stayed.</p><p>The graph is recalculated to reflect this uncertainty by distributing the probability value of <strong>1.0</strong> from node <em>R</em> to each possible choice of node - <em>D</em> (exit) and <em>R</em> (stay). We don‚Äôt know the likeliness of either happening so we can just assume equal chances, giving them <strong>0.5</strong> each.</p><img srcset="" sizes="" alt="Node graph representing the room node with 0.5, the doorway node with 0.5, and hallway nodes with 0.0" src="https://leanrada.com/notes/dynamic-patrol-stealth-games/room-graph-r1d1.png" spec="300" loading="lazy" width="" height=""><p>Now there is 50% probability that the target is in the room, and 50% in the doorway. This process is repeated for each node over time to calculate the target‚Äôs potential location at any given moment.</p><p>Let‚Äôs do another iteration. The next one is a bit tricky, but it‚Äôs all calculated the same. We just need to calculate the distribution from each node <em>in parallel</em>, like so:</p><img srcset="" sizes="" alt="Node graph representing the distribution from previous state" src="https://leanrada.com/notes/dynamic-patrol-stealth-games/room-graph-r1d1t.png" spec="300" loading="lazy" width="" height=""><img srcset="" sizes="" alt="Node graph representing the room node with 0.42, the doorway node with 0.42, and the hallway node H1 directly next to the doorway with 0.16" src="https://leanrada.com/notes/dynamic-patrol-stealth-games/room-graph-r5d5h2.png" spec="300" loading="lazy" width="" height=""><p><strong>Explanation of above:</strong> The <strong>0.5</strong> at <em>R</em> is split into two, giving <strong>0.5 / 2 = 0.25</strong> each to <em>R</em> and <em>D</em>. Meanwhile, the <strong>0.5</strong> at <em>D</em> is split into three, giving <strong>0.5 / 3 ‚âà 0.16</strong> each to <em>R</em>, <em>D</em>, and <em>H1</em>. Then node values are added together in a separate step after the split.</p><p>After some time, we will get a picture of where the target is likely to be and a smarter game AI can utilise this to send guards on a more realistic investigation route.</p><p>Another iteration and we get this:</p><img srcset="" sizes="" alt="Node graph representing the room node with 0.35, the doorway node with 0.39, hallway nodes H0 and H2 with 0.04, and H1 with 0.18" src="https://leanrada.com/notes/dynamic-patrol-stealth-games/room-graph-final.png" spec="300" loading="lazy" width="" height=""><p>What I‚Äôve just described is some generalisation of a <strong><a target="_blank" href="https://en.wikipedia.org/wiki/Markov_chain">Markov chain</a></strong>. Well, it‚Äôs not exactly accurate to call it that since the Markov chain is just one part of the algorithm. You‚Äôll see why in the next section.</p><p><span><strong>Disclaimer:</strong> I wasn‚Äôt thinking about Markov chains while developing this algorithm. The first version back in 2013 was based on crude counting and was more like a potential field. (Btw, it was in <a target="_blank" href="https://en.wikipedia.org/wiki/Adobe_Flash">Flash</a>.) The Markov chain concept that I learned (2023) helped me make the calculations more accurate and the numbers more realistic.</span></p><p>Suppose a guard did come to investigate the nearest highest probability node (the doorway <em>D</em>). Coming from the south, the guard just saw the doorway and the immediate hallway in their field of vision - There are two possibilities: Either <strong>(1)</strong> they saw nothing, or <strong>(2)</strong> they saw <em>the target</em>.</p><p>In case <strong>(1)</strong> where the guard saw nothing, we need to update the seen nodes according to the guard‚Äôs a posteriori observation.</p><img srcset="" sizes="" alt="Node graph with observed nodes having 0.0" src="https://leanrada.com/notes/dynamic-patrol-stealth-games/observe-none.png" spec="300" loading="lazy" width="" height=""><p>The nodes that were seen having no target at their locations are forced to a probability of <strong>0.0</strong>, because if you think about it, that makes sense. The remaining nodes are then scaled so that they still add up to a total of <strong>1.0</strong> (This is an invariant in any case).</p><p>To illustrate, here‚Äôs a table that details each intermediate step:</p><p>After updating the probabilities, the state of the graph tells us that the target is around 90% likely to be in the room <em>R</em> and 10% in the far hallway <em>H0</em>.</p><p>The game AI can simply send the guard to the highest node based on the updated probabilities (this case, the room <em>R</em>). It can do this again and again, which will result in a seemingly organic and responsive searching behaviour from the AI guard. No predefined patrol routes needed.</p><p><span>Another way to go about this is to keep track of probabilities in the form of rational numbers - separately tracking the numerators and the denominators. You only need to store the numerator per node, while there is one global denominator, which is the sum of all the numerators. This is what I did for my demo implementation.</span></p><p>In case <strong>(2)</strong> where the guard saw the target, a similar but more drastic approach applies. The node containing the target is assigned <strong>1.0</strong> while <em>the rest of the nodes in the whole graph</em> are cleared back to <strong>0.0</strong>. The target can only be in one place at at a time!</p><img srcset="" sizes="" alt="Node graph with observed target in node having 1.0" src="https://leanrada.com/notes/dynamic-patrol-stealth-games/observe-target.png" spec="300" loading="lazy" width="" height=""><p>It stays that way as long as the guard can see the target. When the guard loses sight of the target again, we just continue the Markov inference and the probability values will spread again like a wave. The cycle of chasing, investigation, and hiding continues.</p><p>It‚Äôs best to just see it in action. Play with the demo in the following section.</p><p>I implemented this algorithm in JavaScript so you can play with it right here. In this implementation, the world is a 2D grid where each tile is a node in the Markov graph.</p><p>Click a tile to command the target (the green character ) to move. A blue fog will indicate the probabilities of each tile.</p><img src="https://leanrada.com/notes/dynamic-patrol-stealth-games/demo/target.png" alt=""><p>Have fun playing hide and seek!</p><p></p><pre>Interactive content: <a href="https://leanrada.com/notes/dynamic-patrol-stealth-games">See it on leanrada.com.</a>
Alternative text: </pre><p><span><strong>Tip:</strong> Press <code>P</code> to toggle visibility of the probability field. Press <code>N</code> to toggle numbers between none, percentage, and log-scale. (Keyboard only)</span></p><p>Sadly, the name <a target="_blank" href="https://github.com/mxgmn/WaveFunctionCollapse">‚ÄúWave Function Collapse‚Äù</a> has already been claimed by a different video game algorithm, so I can‚Äôt give this one a cool quantum name anymore.</p><p><strong>Bonus demo! 2 guards.</strong></p><p></p><pre>Interactive content: <a href="https://leanrada.com/notes/dynamic-patrol-stealth-games">See it on leanrada.com.</a>
Alternative text: </pre><p>Special thanks:</p><img src="https://leanrada.com/notes/dynamic-patrol-stealth-games/demo/target.png" alt=""><img src="https://leanrada.com/notes/dynamic-patrol-stealth-games/demo/guard.png" alt=""><img src="https://leanrada.com/notes/dynamic-patrol-stealth-games/demo/guard.png" alt=""><img src="https://leanrada.com/notes/dynamic-patrol-stealth-games/demo/guard.png" alt=""><img src="https://leanrada.com/notes/dynamic-patrol-stealth-games/demo/guard.png" alt=""><p><strong>Update:</strong> Related stuff I found:</p>]]></description>
            <link>https://leanrada.com/notes/dynamic-patrol-stealth-games</link>
            <guid isPermaLink="true">https://leanrada.com/notes/dynamic-patrol-stealth-games</guid>
            <pubDate>Fri, 30 Jun 2023 14:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[A review of all IDEs I‚Äôve ever used]]></title>
            <description><![CDATA[<p>
                            Ah, Notepad, the default text editor in Microsoft Windows XP, my OS
                            not-by-choice back when I didn‚Äôt know what ‚Äúprogramming‚Äù was and
                            only cared about making mods for a game called Clonk. The game used
                            a C-like language, but I didn‚Äôt know that nor anything about syntax
                            and syntax coloring and other good editor stuff.
                        </p><p>
                            However, it got the job done. You open a file, you save it. It‚Äôs
                            compatible with any programming language, any build tool. In fact
                            it‚Äôs not incompatible with anything! Except Unix line endings.
                        </p><p>
                            Due to its simplicity and speed (tho it‚Äôs not really fast when large
                            files), I give it a 7/10. Note that Windowses 7/10 being the only
                            good versions of Windows is purely coincidental.
                        </p><img srcset="" sizes="" alt="screenshot of Macromedia Flash 8" src="https://leanrada.com/misc/ide-reviews/macromedia-flash-8.png" spec="100% [800) 800" loading="lazy"><p>
                    This IDE, as you can see, was very much focused on the
                    <strong>graphics and animation</strong> part of the authoring
                    experience, not so much on the programming side of rich Web
                    applications. Scripts existed merely as augmentation of objects in the
                    scene.
                </p><p>
                    I didn‚Äôt care for the graphical, scene-graph-oriented development and
                    preferred pure programming with text and text files. Same reason why I
                    don‚Äôt like the Unity Editor. So it‚Äôs a <strong>6/10</strong> for me.
                </p><p>
                            FlashDevelop was a code-first Flash IDE. My first experience
                            <span>with</span> a
                            <span>‚Äúreal‚Äù</span> programming IDE
                            <span>with</span> refactoring, build
                            configurations, logging, libraries, and more.
                        </p><p>
                            I like how it renders code <span>in</span> bitmap
                            fonts. Very crisp <span>in</span> the old CRT
                            monitors <span>with</span> 800x600 screen
                            resolution. I customized it
                            <span>with</span> some downloaded programming
                            fonts too.
                        </p><p>
                            Extremely lightweight compared to the alternative Adobe Flash.
                            It<span>‚Äôs simple and fast. Plus code completion, snippets, and
                                REFACTORING IN ActionScript!? It‚Äô</span>s a high 9/10.
                        </p><p>
                            My only problem was when some clients wanted the .fla file
                            (Adobe<span>‚Äôs file format for Flash projects). But that‚Äô</span>s not a real problem.
                        </p><p>
                            /* The only reason why I used Code::Blocks in the first place was
                            that it was the IDE recommended for my first programming course when
                            I was taking up CS. It was also preinstalled on the university
                            compsci lab computers.
                        </p><p>
                            It‚Äôs fine. UI was not so great...? I found the build configuration
                            setup confusing and so just ran gcc using cli. Then again it was my
                            first time writing C, and (as I find out later in my career) build
                            configs are always confusing.
                        </p><p>I rate it a good 6/10. */</p><p>
                    I use
                    <a target="_blank" href="https://en.wikipedia.org/wiki/Vi">vi</a> to
                    write commit messages. It was git that trapped me in vi in the first
                    place. I never really learned to use the advanced commands in vi, as I
                    only use it to write in English - as in commit messages.
                </p><p>
                    My rating would be <code>export EDITOR=nano</code>.
                </p><img srcset="" sizes="" alt="screenshot of Eclipse" src="https://leanrada.com/misc/ide-reviews/eclipse.png" spec="100% [800) 800" loading="lazy"><p>
                    Eclipse was <em>the</em> Java IDE a few years back. It was even the
                    official IDE for developing Android apps for a while. How the mighty
                    have
                    <a target="_blank" href="https://movingfulcrum.com/the-fall-of-eclipse/">fallen</a>.
                </p><p>
                    I used Eclipse throughout college for Java courses, and in my first job
                    working on Java backends and Android apps. It was a very big app, in
                    terms of features and memory usage.
                </p><p>
                    Unfortunately, it was really slow. It‚Äôs like waiting for an eclipse. At
                    work, I used to come in at like 9:30AM, boot up the computer, start up
                    Eclipse, then immediately go get some snacks. After 5 minutes the toast
                    is ready. 10 minutes later, Eclipse becomes usable and I could finally
                    work.
                </p><p>
                    It‚Äôs a <strong>4/10</strong> for me, due to slow performance. I‚Äôd rather
                    use a text editor, if I only knew how the JARs and the APKs got built.
                </p><img srcset="" sizes="" alt="screenshot of Android Studio" src="https://leanrada.com/misc/ide-reviews/android-studio.png" spec="100% [800) 800" loading="lazy"><p>
                    Android Studio saved my productivity as an Android dev. Sadly, that
                    meant no more snacks while starting up the IDE. And no more naps while
                    compiling. I guess JetBrains saved the Android development experience as
                    a whole, from Android Studio to Kotlin and Compose.
                </p><p>
                    It was still kinda slow at startup (?), ‚Äòcause of all the indexing going
                    on. JetBrains really redefined IDEs with their Indexing Development
                    Environments.
                </p><p>
                    Still pretty good and still getting better. Search anywhere is awesome.
                    The refactoring shortcuts are great. Android tools unmatched. Good
                    <strong>9/10</strong>. (Only problem is memory usage üëé)
                </p><p>
                            Best text editor. Not an IDE per se, but it could be. Very snappy.
                            Simple and easy-to-use with some advanced tricks.
                        </p><p>
                            I believe they also invented the minimap. Both the minimap and the
                            command palette are super useful features. It‚Äôs also quite
                            customizable and could be turned into a semi-IDE with build
                            commands.
                        </p><p>
                            Due to Sublime Text I‚Äôve grown to love the simpler, more
                            minimalistic tools. It‚Äôs life-changing. 10/10
                        </p><p>
                            VS Code is the new Sublime Text. This has been my main tool in many
                            projects for a long time now.
                        </p><p>
                            Sublime Text is still faster, I think, but I haven‚Äôt really compared
                            them in a long time. I still use Sublime Text keybindings though.
                            Muscle memory.
                        </p><p>
                            As a web dev, I like the built-in web browser so I could just open
                            the page I‚Äôm working on and its source code side-by-side. And
                            TypeScript / JavaScript support is strong.
                        </p><p>
                            Even outside of web development, the plugin marketplace is very
                            extensive, and almost every language / workflow is supported.
                        </p><p>
                    Cider V is an internal cloud-based editor used at Google. It‚Äôs like this
                    <a target="_blank" href="https://github.dev/Kalabasa/kalabasa.github.io/blob/src/src/site/misc/ide-reviews/index.html">cloud-based code editor</a>, but for Google‚Äôs internal monorepo. It‚Äôs based on VS Code and pretty
                    much behaves just like VS Code but with internal extensions.
                </p><p>
                    The best thing about it is its
                    <a target="_blank" href="https://ai.googleblog.com/2022/07/ml-enhanced-code-completion-improves.html">AI-powered autocomplete</a>, trained on Google‚Äôs own huge repository of code. Most (not all) of
                    the time it just suggests what‚Äôs in my mind before it even exists in my
                    mind.
                </p><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4vLV_OWhGUw9u2badD0ZlCFdl1mwBlYzQCQ_XRTtCyu2DKy-yGZhKgnRvruSrAdqQOpThDNi0lbpHjSn5b18aqJ-pJnvCZTEOgrpyVO75CWGTugrrN4e_RY65v_bUdLkOvmDBI9v2j3qA7pWaUAeorGXUzAYHShoNff52lK1lSd2u1seEOSn9JW7hvg/s1043/image5.gif" alt="demo of autcompletion" loading="lazy"><p>
                    However, the normal dumb autcompletion sometimes doesn‚Äôt work (or is
                    slow?) which gets frustrating. tbf, I get that in VS Code too when
                    working on very large projects.
                </p><p>
                    I haven‚Äôt used GitHub Copilot + VS Code so I don‚Äôt have a reference for
                    comparison. I rate this <strong>9/10</strong>.
                </p><img srcset="" sizes="" alt="screenshot of IntelliJ IDEA" src="https://leanrada.com/misc/ide-reviews/idea.png" spec="100% [800) 800" loading="lazy"><p>
                    Great Java and Kotlin IDE. I love the refactoring tools. Also, the data
                    flow analysis tool is great for debugging.
                </p><p>
                    But it‚Äôs slow and heavy sometimes. Must be the indexing. For me, a slow
                    tool really ruins the flow of work and decreases productivity. IDEA
                    makes up for it due to its features, so it‚Äôs tolerable.
                </p><p>
                    As a Java IDE (without the Android goodness of Android Studio), it only
                    gets
                    <strong>8.5/10</strong>.
                </p><img srcset="" sizes="" alt="screenshot of IntelliJ IDEA" src="https://leanrada.com/misc/ide-reviews/idea.png" spec="100% [800) 800" loading="lazy"><p>
                    This is the paid version of the above. Uh, I really didn‚Äôt notice any
                    difference from the Community edition besides the splash screen. It‚Äôs
                    rated <strong>8.5/$</strong>.
                </p>]]></description>
            <link>https://leanrada.com/misc/ide-reviews</link>
            <guid isPermaLink="true">https://leanrada.com/misc/ide-reviews</guid>
            <pubDate>Tue, 20 Jun 2023 14:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[How I built tic-tac-toe game AI in pure CSS]]></title>
            <description><![CDATA[<p>As a software developer, I‚Äôm always looking for new and fun ways to challenge myself. Some time ago, I decided to implement tic-tac-toe with AI using only <strong>HTML</strong> and <strong>CSS</strong>. That is, no JavaScript! We already knew about the possibility of advanced CSS interactions (e.g. fancy checkboxes), but I wanted to see how far I could take it.</p><p>Here‚Äôs a CodePen of it! Can you beat a style sheet in a game of tic-tac-toe?</p><p data-height="700" data-theme-id="dark" data-default-tab="result" data-slug-hash="oVMOZK" data-user="kalabasa">
                            <span>See the Pen <a href="https://codepen.io/kalabasa/pen/oVMOZK">
                                    Pure CSS Tic Tac Toe AI</a> by Kalabasa (<a href="https://codepen.io/kalabasa">@kalabasa</a>)
                                on <a href="https://codepen.io">CodePen</a>.</span>
                        </p><p>In this post, I‚Äôll write about the steps I took to make it, starting with the fundamentals.</p><p>Before starting to build anything complex, it‚Äôs important to start small and think about the basic elements. Unlike JavaScript, HTML and CSS are declarative languages. We can‚Äôt have procedures or functions, control flow, if-statements, and the like. Instead what we have are markup and rules. We‚Äôll build upon these rules to create complex game logic.</p><p>For starters, let‚Äôs do something that‚Äôs fairly common on the web: <strong>custom checkbox styles</strong>.</p><p>To do this, we need an extra element for the checkbox visuals, like an empty span element.</p><pre><code><span><span><span>&lt;</span>label</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>checkbox<span>"</span></span> <span>/&gt;</span></span> <span><span><span>&lt;</span>span</span><span>&gt;</span></span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span> Check this out
<span><span><span>&lt;/</span>label</span><span>&gt;</span></span></code></pre><p>On the CSS side, the real checkbox input is hidden, while the span is styled as a checkbox in its stead.</p><p>Now here‚Äôs the important part, we‚Äôll use the <code>:checked</code> pseudo-class and the <strong>sibling combinator</strong> <code>~</code> to make it all work. The checked pseudo-class selector reacts to the checkbox input‚Äôs state, while the sibling combinator makes it possible to apply the styles on the separate fake checkbox element.</p><pre><code><span>input:checked ~ span</span> <span>{</span>
  <span>background-color</span><span>:</span> red<span>;</span>
  <span>transform</span><span>:</span> <span>rotate</span><span>(</span>45deg<span>)</span><span>;</span>
<span>}</span></code></pre><p>Custom checkboxes! Easy.</p><p>The sibling combinator has uses beyond styling boxes next to inputs. We can perform some ‚Äúaction at a distance‚Äù, for example:</p><p>As you know, when it rains, water falls down from the sky. This may cause undesired wetness. An umbrella is a device which shields the user from falling particles such as the aforementioned rainwater.</p><pre><code><span>input:checked ~ .advice .take-umbrella</span> <span>{</span>
    <span>visibility</span><span>:</span> visible<span>;</span>
<span>}</span>
<span>input:checked ~ .advice .no-umbrella</span> <span>{</span>
    <span>visibility</span><span>:</span> hidden<span>;</span>
<span>}</span></code></pre><p>As you‚Äôll see later, the sibling combinator <code>~</code> can be very useful for these types of interactions.</p><p>Let‚Äôs take this to the next level, shall we?</p><p>Using the <code>&lt;label&gt;</code>‚Äôs <code>for</code> attribute, we can get even more action at a distance. We can make pretty much any kind of UI we want!</p><p>Presenting‚Ä¶ the weather-advice-o-matic! üåà Go ahead, press the button!</p><pre>Interactive content: <a href="https://leanrada.com/notes/pure-css-tictactoe-ai">See it on leanrada.com.</a>
Alternative text: </pre><p>A single button is not very exciting, is it? Let‚Äôs add another input and implement an <strong>OR</strong> construct to determine the output. I mean this kind of thing: "if A or B then C".</p><p>In CSS this can be easily achieved by using a <strong>selector list</strong> (i.e., comma-separated selectors).</p><pre><code><span>input#raining:checked ~ .advice .take-umbrella,
input#sunny:checked ~ .advice .take-umbrella</span> <span>{</span>
  <span>visibility</span><span>:</span> visible<span>;</span>
<span>}</span></code></pre><p>Now, weather-advice-o-matic can make decisions based on two parameters!</p><pre>Interactive content: <a href="https://leanrada.com/notes/pure-css-tictactoe-ai">See it on leanrada.com.</a>
Alternative text: </pre><p>(If RAINY or SUNNY then UMBRELLA)</p><p>How about <strong>AND</strong>? We can implement an AND construct too! This involves chaining the inputs together in a single selector using sibling combinators.</p><pre><code><span>input#raining:checked ~ input#windy:checked ~ .advise .take-raincoat</span> <span>{</span>
  <span>visibility</span><span>:</span> visible<span>;</span>
<span>}</span></code></pre><p>What‚Äôs this? Weather-advice-o-matic can now make nuanced decisions! Wow! Careful, it might be sentient!!!</p><pre>Interactive content: <a href="https://leanrada.com/notes/pure-css-tictactoe-ai">See it on leanrada.com.</a>
Alternative text: </pre><p>(If RAINY and WINDY then RAINCOAT)</p><p>Here‚Äôs a summary of what we have so far:</p><pre><code><span>/* if A or B then C */</span>
<span>A ~ C,
B ~ C</span> <span>{</span>
  C
<span>}</span>

<span>/* if A and B then C */</span>
<span>A ~ B ~ C</span> <span>{</span>
  C
<span>}</span></code></pre><p>Another basic computing operator aside from AND and OR is the <strong>NOT</strong> operator. We don‚Äôt really need that here, but for the record, there‚Äôs the <code>:not()</code> pseudo-class in CSS. You can figure that out.</p><p>As a proof of concept and precursor to tic-tac-toe, let‚Äôs look at this three-in-a-row game.</p><pre>Interactive content: <a href="https://leanrada.com/notes/pure-css-tictactoe-ai">See it on leanrada.com.</a>
Alternative text: </pre><p>This is a 3x3 array of checkbox inputs. Internally, each box is numbered 1 to 9 starting from the top-left box going left-to-right row-wise.</p><p>Here are the rules for implementing the win condition in CSS:</p><pre><code><span>#1:checked ~ #2:checked ~ #3:checked ~ .win,
#4:checked ~ #5:checked ~ #6:checked ~ .win,
#7:checked ~ #8:checked ~ #9:checked ~ .win,
#1:checked ~ #4:checked ~ #7:checked ~ .win,
#2:checked ~ #5:checked ~ #8:checked ~ .win,
#3:checked ~ #6:checked ~ #9:checked ~ .win,
#1:checked ~ #5:checked ~ #9:checked ~ .win,
#3:checked ~ #5:checked ~ #7:checked ~ .win</span> <span>{</span>
  <span>visibility</span><span>:</span> visible<span>;</span>
<span>}</span></code></pre><p>Yes, it‚Äôs kinda hacky, but that is expected when you force logic into CSS. For comparison, the CSS for tic-tac-toe goes over 9000 lines! I never said it would be clean.</p><p>Anyway, these 8 lines correspond to the 8 possible ways to win the game. The 3-input AND rule (remember AND rules?) in each line covers <em>every possible winning combination</em>. The pseudocode in the comment helps illustrate this:</p><pre><code><span>/*
 * if
 *      ([#1 marked] and [#2 marked] and [#3 marked]) // top row
 *   or ([#4 marked] and [#5 marked] and [#6 marked]) // middle row
 *   or ([#7 marked] and [#8 marked] and [#9 marked]) // bottom row
 *   .
 *   :
 *   or ([#3 marked] and [#5 marked] and [#7 marked]) // upward diagonal
 * then
 *   [win]
 */</span>
<span>#1:checked ~ #2:checked ~ #3:checked ~ .win,
#4:checked ~ #5:checked ~ #6:checked ~ .win,
#7:checked ~ #8:checked ~ #9:checked ~ .win,
#1:checked ~ #4:checked ~ #7:checked ~ .win,
#2:checked ~ #5:checked ~ #8:checked ~ .win,
#3:checked ~ #6:checked ~ #9:checked ~ .win,
#1:checked ~ #5:checked ~ #9:checked ~ .win,
#3:checked ~ #5:checked ~ #7:checked ~ .win</span> <span>{</span>
  <span>visibility</span><span>:</span> visible<span>;</span>
<span>}</span></code></pre><p>So far, the order of your inputs doesn‚Äôt matter. You can even undo your inputs by unchecking the boxes (Try it above). That won‚Äôt fly in a game of tic-tac-toe, where we take turns incrementally marking the board. No backsies!</p><p>We need a way to <strong>‚Äúconsume‚Äù</strong> inputs. We can do this by hiding the inputs or otherwise making them unclickable. This is just a trick, of course, as we can‚Äôt really disable inputs using CSS. But it works fine for the typical mouse and touch users.</p><p>So for tic-tac-toe, what I did was define multiple sets of the 3x3 input board, that is, one set of inputs for each turn. Stacked on top of each other, each set is only interactable on its turn.</p><video muted="" autoplay="" loop="" aria-label="input sets illustration">
                                <source src="https://leanrada.com/notes/pure-css-tictactoe-ai/input_sets.mp4">
                                <a href="https://leanrada.com/notes/pure-css-tictactoe-ai/input_sets.mp4">input sets illustration</a>
                            </video><pre><code><span>/* Disable turn 1 inputs when turn 1 is played */</span>
<span>input[name="turn_1"]:checked ~ input[name="turn_1"]</span> <span>{</span>
    <span>pointer-events</span><span>:</span> none<span>;</span>
<span>}</span>
<span>/* Enable next turn's inputs */</span>
<span>input[name="turn_1"]:checked ~ input[name="turn_2"]</span> <span>{</span>
    <span>pointer-events</span><span>:</span> all<span>;</span>
<span>}</span>
<span>/* And so on... */</span></code></pre><p>Here‚Äôs little a demo of sequential inputs:</p><p><span>I was only able to implement up to three turns here. The exponential growth of rules has gotten really tedious to write!</span></p><pre>Interactive content: <a href="https://leanrada.com/notes/pure-css-tictactoe-ai">See it on leanrada.com.</a>
Alternative text: </pre><p>With the power of sequencing, we‚Äôre starting to recreate the power of state machines and procedural programming!</p><img srcset="" sizes="" alt="Look What They Need To Mimic A Fraction Of Our Power meme" src="https://leanrada.com/notes/pure-css-tictactoe-ai/meme.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><p>Tic-tac-toe is a <a target="_blank" href="https://en.wikipedia.org/wiki/Solved_game">solved game</a>, which means there exists a perfect strategy. For every move, there is a known optimal counter move.</p><p>This is perfect for CSS as it‚Äôs just a bunch of static declarations. We can list all of the optimal moves and directly translate them into CSS declarations!</p><p>As a side-effect, the AI would never lose. But that‚Äôs not a bad thing at all. Here, the CSS will style on you.</p><p>The rules are essentially a bunch of if-then statements for every scenario. Here are a couple of them:</p><p>Example rule: <em>If <strong>X(1)</strong> and <strong>X(2)</strong> then <strong>O(3)</strong>.</em></p><p>In English, if an X was played at box #1 (top-left) and another X is at #2 (top-center), then block the top row by playing O at box #3 (top-right).</p><p>(In these examples, X is the player and O is the AI.)</p><p>In CSS, that translates to:</p><pre><code><span>input[value="1"]:checked
~ input[value="2"]:checked
~ .o3</span> <span>{</span>
  <span>visibility</span><span>:</span> visible<span>,</span>
<span>}</span></code></pre><video muted="" autoplay="" loop="" aria-label="blocking rule animation">
                                <source src="https://leanrada.com/notes/pure-css-tictactoe-ai/blocking.mp4">
                                <a href="https://leanrada.com/notes/pure-css-tictactoe-ai/blocking.mp4">blocking rule animation</a>
                            </video><p>Another example: <em>If <strong>O(3)</strong> and <strong>O(7)</strong> then <strong>O(5)</strong>.</em></p><p>If O is at box #3 (top-right) and another O is at #7 (bottom-left), then win diagonally by playing O at box #5 (center).</p><p>Now, this rule needs knowledge of the AI‚Äôs previous moves. But we can‚Äôt really check for that as they‚Äôre not inputs. There is no direct translation of <strong>O(3)</strong> and <strong>O(7)</strong> into CSS conditions.</p><p>But since the AI is deterministic, we already know how those previous <em>O</em>s came about. They‚Äôre just responses to previous inputs as defined in previous rules! So, for example, we can substitute <strong>O(3)</strong> with the inputs that produced it, such as <strong>X(1)</strong> &amp; <strong>X(2)</strong>.</p><pre><code>input[value=<span>"1"</span>]<span>:</span>checked
~ input[value=<span>"2"</span>]<span>:</span>checked <span>/* We know X(1) and X(2) produces O(3) */</span>
~ input[value=<span>"4"</span>]<span>:</span>checked <span>/* X(1) and X(4) produces O(7) */</span>
<span>.o5</span> <span>{</span>
  <span>visibility</span><span>:</span> visible<span>,</span>
<span>}</span>
<span>/* Therefore, X(1) &amp; X(2) &amp; X(4) is equivalent to O(3) &amp; O(7). */</span>
<span>/* If X(1) &amp; X(2) &amp; X(4) then O(5) is a winning move! */</span></code></pre><p>Alright, so the game AI is really just a bunch of if-statements of the form <em>‚Äúif [inputs leading up to a scenario], then [show optimal response]‚Äù</em>, <strong>for every scenario</strong>. Problem is, how do we find all the possible scenarios and corresponding optimal moves? Is there a list of all the optimal moves somewhere, like a cheatsheet?</p><p>Actually, there is one, but it‚Äôs for humans.</p><img alt="" src="https://imgs.xkcd.com/comics/tic_tac_toe.png" loading="lazy"><p>It‚Äôs not really feasible to write rules based on this by hand, unless you have more than 60,480 hours to spare.</p><p>What I did was write some kind of <a target="_blank" href="https://en.wikipedia.org/wiki/Minimax">minimax algorithm</a> to generate all the rules. The algorithm semi-exhaustively searched the game state space, while recording the moves that lead to a win or a draw, and saved those moves as rules.</p><p>I lost the original code (trashed it after finishing the project), but here‚Äôs an untested recreation of the algorithm:</p><pre><code><span>/**
 * Evaluates a game state having these parameters: last plays of player X,
 * the player who has the current turn, and the current board state.
 *
 * Along the way, prints CSS rules for O's plays.
 *
 * Returns the endgame for O: WIN, LOSS, or a DRAW. Assuming optimal play.
 */</span>
<span>function</span> <span>evaluate</span><span>(</span>xPlays<span>:</span> number<span>[</span><span>]</span><span>,</span> <span>currentTurn</span><span>:</span> <span>'X'</span> <span>|</span> <span>'O'</span><span>,</span> <span>board</span><span>:</span> <span>(</span><span>'X'</span> <span>|</span> <span>'O'</span> <span>|</span> <span>null</span><span>)</span><span>[</span><span>]</span><span>)</span> <span>{</span>

  <span>// checkWinner checks for a 3-in-a-row and returns the winner.</span>
  <span>let</span> winner <span>=</span> <span>checkWinner</span><span>(</span>board<span>)</span>
  <span>if</span> <span>(</span>winner <span>==</span> <span>'X'</span><span>)</span> <span>return</span> <span>LOSS</span>
  <span>else</span> <span>if</span> <span>(</span>winner <span>==</span> <span>'O'</span><span>)</span> <span>return</span> <span>WIN</span>
  <span>else</span> <span>if</span> <span>(</span>xPlays<span>.</span>length <span>==</span> <span>5</span><span>)</span> <span>return</span> <span>DRAW</span> <span>// Board full (5 Xs implies 4 Os)</span>


  <span>if</span> <span>(</span>currentTurn <span>==</span> <span>'O'</span><span>)</span> <span>{</span>
    <span>// Brute-force find the optimal play for O</span>
    <span>let</span> optimal <span>=</span> <span>null</span>
    <span>let</span> winnable <span>=</span> <span>false</span>
    <span>for</span> <span>(</span>i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>9</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
      <span>if</span> <span>(</span>board<span>[</span>i<span>]</span><span>)</span> <span>continue</span>

      board<span>[</span>i<span>]</span> <span>=</span> <span>'O'</span>
      <span>const</span> result <span>=</span> <span>evaluate</span><span>(</span>xPlays<span>,</span> <span>'X'</span><span>,</span> board<span>)</span>
      board<span>[</span>i<span>]</span> <span>=</span> <span>null</span>

      <span>if</span> <span>(</span>result <span>==</span> <span>DRAW</span><span>)</span> <span>{</span>
        <span>// This play will lead to a draw. Save it for now.</span>
        optimal <span>=</span> i
      <span>}</span> <span>else</span> <span>if</span> <span>(</span>result <span>==</span> <span>WIN</span><span>)</span> <span>{</span>
        <span>// This play will lead to a win. This is it.</span>
        optimal <span>=</span> i
        winnable <span>=</span> <span>true</span>
        <span>break</span>
      <span>}</span> <span>// No else. Discard play that would lead to LOSS.</span>
    <span>}</span>

    <span>if</span> <span>(</span>optimal <span>==</span> <span>null</span><span>)</span> <span>{</span>
      <span>// No winning play nor draws found. All paths lead to loss.</span>
      <span>return</span> <span>LOSS</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>// Optimal play found. Print rule.</span>
      <span>printCSS</span><span>(</span>xPlays<span>,</span> optimal<span>)</span>
      <span>return</span> winnable <span>?</span> <span>WIN</span> <span>:</span> <span>DRAW</span>
    <span>}</span>
  <span>}</span> <span>else</span> <span>{</span> <span>// currentTurn == 'X'</span>
    <span>// We don't know what the player would play</span>
    <span>// So evaluate every possibe play</span>
    <span>let</span> loseable <span>=</span> <span>false</span>
    <span>for</span> <span>(</span>i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>9</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
      <span>if</span> <span>(</span>board<span>[</span>i<span>]</span><span>)</span> <span>continue</span>

      board<span>[</span>i<span>]</span> <span>=</span> <span>'X'</span>
      <span>const</span> result <span>=</span> <span>evaluate</span><span>(</span><span>[</span><span>...</span>xPlays<span>,</span> i<span>]</span><span>,</span> <span>'O'</span><span>,</span> board<span>)</span>
      board<span>[</span>i<span>]</span> <span>=</span> <span>null</span>

      <span>if</span> <span>(</span>result <span>==</span> <span>LOSS</span><span>)</span> loseable <span>=</span> <span>true</span>
    <span>}</span>

    <span>// Assume player plays optimally. If they can win from current state,</span>
    <span>// then immediately presume LOSS. This will factor into O's turn evaluation</span>
    <span>// above, where any play that leads to LOSS is discarded.</span>
    <span>if</span> <span>(</span>loseable<span>)</span> <span>return</span> <span>LOSS</span>

    <span>// Not loseable, either winnable or drawable.</span>
    <span>// Returning DRAW allows both paths to be evaluated.</span>
    <span>return</span> <span>DRAW</span>
  <span>}</span>
<span>}</span></code></pre><p>And here‚Äôs the function that outputs CSS:</p><pre><code><span>/**
 * Print CSS rule for the given game state and O's next play.
 */</span>
<span>function</span> <span>printCSS</span><span>(</span><span><span>xPlays</span><span>:</span> number<span>[</span><span>]</span><span>,</span> <span>oPlay</span><span>:</span> number</span><span>)</span> <span>{</span>
  css <span>+=</span> xPlays
    <span>.</span><span>map</span><span>(</span><span>(</span><span>pos<span>,</span> turn</span><span>)</span> <span>=&gt;</span>
        <span><span>`</span><span>input[name='turn_</span><span><span>${</span>turn<span>}</span></span><span>'][value='</span><span><span>${</span>pos<span>}</span></span><span>']:checked</span><span>`</span></span><span>)</span>
    <span>.</span><span>join</span><span>(</span><span>' ~ '</span><span>)</span>
    <span>+</span> <span><span>`</span><span> ~ .o</span><span><span>${</span>oPlay<span>}</span></span><span>`</span></span>
    <span>+</span> <span>' { visibility: visible; }'</span>
<span>}</span></code></pre><p>The CSS output is directly used in the game. Debugging this was a pain, but luckily I only got a couple of miscalculations (if I recall correctly).</p><p>It was a very interesting project. I‚Äôm curious how far CSS machines like this could go. A JS to CSS transpiler, perhaps?</p><p>This project serves as a reminder that there are always new and exciting ways to waste our time doing impractical things, and that sometimes fun solutions come from thinking outside of the (check)box.</p><p><a target="_blank" href="https://codepen.io/kalabasa/pen/oVMOZK">Here‚Äôs the link to the CodePen!</a>
                        </p>]]></description>
            <link>https://leanrada.com/notes/pure-css-tictactoe-ai</link>
            <guid isPermaLink="true">https://leanrada.com/notes/pure-css-tictactoe-ai</guid>
            <pubDate>Thu, 04 May 2023 14:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Developing a bitwise keyboard input method]]></title>
            <description><![CDATA[<p>This post is about how I achieved the power of 15 keys using just 4 keys on the keyboard. I go over the motivation, the design, and the implementation. At the end, I wrap the solution into a small library. Maybe you‚Äôll find it useful!</p><p>I use a compact keyboard called the <strong>Lily58</strong> as my main keyboard. It‚Äôs a column-staggered split keyboard.</p><img srcset="" sizes="" alt="Photo of a Lily58 keyboard" src="https://leanrada.com/notes/developing-bitwise-input-method/lily58.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><p>As the name implies, it has only 58 buttons instead of the normal 80+ buttons. Space was limited and it was hard to fit all the letters, numbers, symbols, and other unique keys that I need.</p><p>The function keys (F1, F2, F3, etc) were particularly cumbersome. I don‚Äôt use them very often, yet they take a lot of space. You can see with my previous function key layout that they‚Äôre not very space-efficient:</p><img srcset="" sizes="" alt="" src="https://leanrada.com/notes/developing-bitwise-input-method/prevlayout.png" spec="100% [664) 664" loading="lazy" width="" height=""><p>Luckily, the Lily58 is <strong>programmable</strong>! Using the framework slash firmware called <a target="_blank" href="https://qmk.fm/">QMK</a>, I can program the keyboard to add whatever functionality I wanted. And that‚Äôs exactly how I optimized the function keys‚Äô space usage.</p><p>To make space for other keys, I devised a different way to input function keys, a <strong>bitwise input scheme</strong>. In this scheme, you input in terms of bits; there is one key for each bit. For example, take four keys; if we assign them to bits 1, 2, 4, and 8, we can represent any number from 0 to 15 by pressing a combination of those keys.</p><pre>Interactive content: <a href="https://leanrada.com/notes/developing-bitwise-input-method">See it on leanrada.com.</a>
Alternative text: </pre><p>With 15 different combinations, we have more than enough inputs to cover the function keys! Each decimal number is directly mapped to a function key in a 1-to-1 correspondence. For example, pressing the bit combination for decimal 1 will input F1, pressing the combination for decimal 2 will input F2, and so on.</p><p>Did you know that there are 24 function keys in total?</p><p>These are the F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, F11, F12, F13, F14, F15, F16, F18, F19, F20, F21, F22, F23, and F24 keys.</p><p>Bit wise, we‚Äôd need just 5 bits - 5 keys to cover all 24 function keys.</p><p>So how does it work? Let‚Äôs dive into the practical details.</p><p>First of all, the implementation doesn‚Äôt care about timing, so you can press the buttons as sloppily as you want. The key thing is that the algorithm waits for you to release all the buttons before committing the resulting combination.</p><p>To do any of this, we need a way to keep track of the state of the bits. Let‚Äôs use an unsigned integer variable to store it.</p><p>When a button is pressed, its corresponding bit is set to 1. But when released, we do not necessarily clear the bit back to 0. There will be a separate mechanism for flushing the accumulated bits.</p><p>Let‚Äôs call the variable <code>accumulator</code>.</p><pre><code>static uint8_t accumulator <span>=</span> <span>0</span><span>;</span>

void <span>on_press</span><span>(</span>uint16_t keycode<span>)</span> <span>{</span>
  int index <span>=</span> <span>get_bit_index</span><span>(</span>keycode<span>)</span><span>;</span>
  <span>if</span> <span>(</span>index <span>==</span> <span>-</span><span>1</span><span>)</span> <span>return</span><span>;</span>

  accumulator <span>|</span><span>=</span> <span>(</span><span>1</span> <span>&lt;</span><span>&lt;</span> index<span>)</span><span>;</span>
<span>}</span></code></pre><p>Now, the accumulated bits will only be evaluated when all of the buttons have been released. A quick way of knowing when that happens is to watch for the last button to be released. To do this, another integer variable tracks how many buttons are currently being pressed.</p><pre><code><span>// Keep count of keys being pressed</span>
static int8_t pressed_keys <span>=</span> <span>0</span><span>;</span>
static uint8_t accumulator <span>=</span> <span>0</span><span>;</span>

void <span>on_press</span><span>(</span>uint16_t keycode<span>)</span> <span>{</span>
  int index <span>=</span> <span>get_bit_index</span><span>(</span>keycode<span>)</span><span>;</span>
  <span>if</span> <span>(</span>index <span>==</span> <span>-</span><span>1</span><span>)</span> <span>return</span><span>;</span>

  <span>// Count key being pressed</span>
  pressed_keys<span>++</span><span>;</span>

  accumulator <span>|</span><span>=</span> <span>(</span><span>1</span> <span>&lt;</span><span>&lt;</span> index<span>)</span><span>;</span>
<span>}</span>

void <span>on_release</span><span>(</span>uint16_t keycode<span>)</span> <span>{</span>
  int index <span>=</span> <span>get_bit_index</span><span>(</span>keycode<span>)</span><span>;</span>
  <span>if</span> <span>(</span>index <span>==</span> <span>-</span><span>1</span><span>)</span> <span>return</span><span>;</span>

  <span>// Count key being released</span>
  pressed_keys<span>--</span><span>;</span>
<span>}</span></code></pre><p>Once the last button is released, it is time to flush the input. The resulting decimal number is mapped to a function key that will finally be sent to the computer.</p><pre><code>void <span>on_release</span><span>(</span>uint16_t keycode<span>)</span> <span>{</span>
  int index <span>=</span> <span>get_bit_index</span><span>(</span>keycode<span>)</span><span>;</span>
  <span>if</span> <span>(</span>index <span>==</span> <span>-</span><span>1</span><span>)</span> <span>return</span><span>;</span>

  pressed_keys<span>--</span><span>;</span>

  <span>// When all keys have been released, flush the input</span>
  <span>if</span> <span>(</span>pressed_keys <span>&lt;=</span> <span>0</span><span>)</span> <span>{</span>
    <span>// Map accumulated value to the corresponding F-key code</span>
    <span>send_to_computer</span><span>(</span>FUNCTION_KEYS<span>[</span>accumulator<span>]</span><span>)</span><span>;</span>

    <span>// Reset state for next round</span>
    pressed_keys <span>=</span> <span>0</span><span>;</span>
    accumulator <span>=</span> <span>0</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre><p>And that‚Äôs about it! This is how I got more space on my keyboard. As a bonus, it forces me to practice converting decimal to binary! üòÇ</p><p>Of course, the code shown here skips some details and totally lacks integration with the QMK framework, but you get the gist.</p><p>There‚Äôs one limitation to this approach though: you cannot hold down a function key. It will only send the function key at the end when the last button has been released. I haven‚Äôt found a need to hold down function keys so it‚Äôs not a problem for me right now.</p><p>I recreated the algorithm in JavaScript/Web as a live demo here! Try it out!</p><pre>Interactive content: <a href="https://leanrada.com/notes/developing-bitwise-input-method">See it on leanrada.com.</a>
Alternative text: </pre><p>If you use QMK you can easily integrate this with your own keymap. Here‚Äôs a step-by-step on how you may use this utility:</p><p>First, define the keys you want to use as bit input in an array called <code>bitwise_f_keys</code>.</p><p>For example, if you wanted to repurpose F1, F2, F3, and F4 to represent the four bits, write the following in your <code>keymap.c</code>:</p><pre><code>const uint16_t bitwise_f_keys<span>[</span><span>]</span> <span>=</span> <span>{</span> KC_F1<span>,</span> KC_F2<span>,</span> KC_F3<span>,</span> KC_F4 <span>}</span><span>;</span>
uint8_t NUM_BITWISE_F_KEYS <span>=</span>
    <span>sizeof</span><span>(</span>bitwise_f_keys<span>)</span> <span>/</span> <span>sizeof</span><span>(</span>uint16_t<span>)</span><span>;</span></code></pre><p>Note: <code>NUM_BITWISE_F_KEYS</code> is also required.</p><p>Hook it up by calling <code>process_bitwise_f()</code> at the top of your <code>process_record_user()</code>.</p><pre><code>bool <span>process_record_user</span><span>(</span>uint16_t keycode<span>,</span> keyrecord_t <span>*</span>record<span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>!</span><span>process_bitwise_f</span><span>(</span>keycode<span>,</span> record<span>)</span><span>)</span> <span>return</span> <span>false</span><span>;</span>

  <span>/* ... */</span>

  <span>return</span> <span>true</span><span>;</span>
<span>}</span></code></pre><p>Finally, copy <a target="_blank" href="https://raw.githubusercontent.com/Kalabasa/qmk_firmware/2d1608287bb8b52669255266472975875f7c2423/keyboards/lily58/keymaps/Kalabasa/features/bitwise_f.h"><code>bitwise_f.h</code></a> and <a target="_blank" href="https://raw.githubusercontent.com/Kalabasa/qmk_firmware/2d1608287bb8b52669255266472975875f7c2423/keyboards/lily58/keymaps/Kalabasa/features/bitwise_f.c"><code>bitwise_f.c</code></a> into your keymap directory, and include <code>bitwise_f.c</code> in your <code>rules.mk</code> build file.</p><p>Don‚Äôt forget to <code>#include "dir/where/you/copied/bitwise_f.h"</code> in your <code>keymap.c</code>!</p><p><span>Props to reddit user hakbraley for helping improve the code!</span>
                        </p>]]></description>
            <link>https://leanrada.com/notes/developing-bitwise-input-method</link>
            <guid isPermaLink="true">https://leanrada.com/notes/developing-bitwise-input-method</guid>
            <pubDate>Wed, 15 Mar 2023 13:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Simple image recognition with vanilla JavaScript]]></title>
            <description><![CDATA[<p>Hi there! I want to share my experience with an <a target="_blank" href="https://en.wikipedia.org/wiki/Computer_vision#Recognition"><strong>image recognition</strong></a> problem I faced in an art project (It was an <a target="_self" href="https://leanrada.com/wares/dimensions">augmented reality art project</a>).</p><img srcset="" sizes="" alt="Image recognition illustration" src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/image-recognition.png" spec="100% [664) 664" loading="lazy" width="" height=""><p>As part of the project, I needed a mobile app to be able to recognize a particular art piece. Then it can overlay virtual effects onto the real-world image. The goal was to have a unique and engaging experience!</p><video muted="" autoplay="" loop="" aria-label="Demo video">
                                <source src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/demo.mp4">
                                <a href="https://leanrada.com/notes/simple-image-recognition-vanilla-js/demo.mp4">Demo video</a>
                            </video><p>There are various solutions available for tackling this problem, ranging from basic histogram matching to advanced convolutional neural networks. There are even libraries that can provide a solution right out of the box! But I decided to take on the challenge of developing my own solution instead of relying on existing tools. Not only did this allow me to learn something new, but it also let me have some fun approaching the problem!</p><p><span><strong>TL;DR</strong> - It converts the camera image into a feature vector and then compares that against a predefined target reference.</span></p><p>To begin solving the problem, we first need to understand the mechanics. It all starts by capturing an image from the camera.</p><p>Now, it‚Äôs important to keep in mind that the camera‚Äôs perception of color can be influenced by various factors. Factors include the lighting conditions in the room or the quality of the camera itself. We need to account for these variables in our solution.</p><img srcset="" sizes="" alt="diagram" src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/tc-vs-pc.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><p>Simply comparing raw pixel data against the target image would likely fail due to the unknown environmental factors. One way of addressing this is to massage the input to isolate the true color from the environmental factors.</p><p>For this, I created a graphical model for the perceived color. It‚Äôs roughly based on CGI illumination models. This was the key to making the image recognition algorithm more robust.</p><p>Here‚Äôs the equation:</p><pre><code>PC = TC * a + b
</code></pre><p>The algorithm begins by calculating the average colors of three predetermined regions within the image. While these regions are specific to my art piece, you can adapt the algorithm to work with any configuration of (at least) three regions.</p><img srcset="" sizes="" alt="diagram" src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/dimensions_illo2.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><p>Let‚Äôs call the three colors <code>PC1</code>, <code>PC2</code>, and <code>PC3</code>.</p><p>To get the average, you can either (1) read over the pixels in those regions and average them, or (2) downsample the image and directly use pixel colors (typically faster). For this case, I used the former, which is reading over the pixels within each region to calculate the average color.</p><pre><code><span>// &lt;video&gt; element streams the camera, not shown here how</span>
video <span>=</span> document<span>.</span><span>getElementById</span><span>(</span><span>'video'</span><span>)</span><span>;</span>
<span>// &lt;canvas&gt; to hold a video frame for reading pixels</span>
canvas <span>=</span> document<span>.</span><span>getElementById</span><span>(</span><span>'canvas'</span><span>)</span><span>;</span> 

<span>// Capture a video frame into the canvas</span>
<span>const</span> canvasContext <span>=</span> canvas<span>.</span><span>getContext</span><span>(</span><span>'2d'</span><span>)</span><span>;</span>
canvasContext<span>.</span><span>drawImage</span><span>(</span>video<span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> width<span>,</span> height<span>)</span><span>;</span>
<span>const</span> imageData <span>=</span> canvasContext
    <span>.</span><span>getImageData</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> width<span>,</span> height<span>)</span>
    <span>.</span>data<span>;</span>

<span>// Get the colors</span>
<span>const</span> pc1 <span>=</span> <span>getRegionAverageColor</span><span>(</span>imageData<span>,</span> regionRect1<span>)</span><span>;</span>
<span>const</span> pc2 <span>=</span> <span>getRegionAverageColor</span><span>(</span>imageData<span>,</span> regionRect2<span>)</span><span>;</span>
<span>const</span> pc3 <span>=</span> <span>getRegionAverageColor</span><span>(</span>imageData<span>,</span> regionRect3<span>)</span><span>;</span>

<span>function</span> <span>getRegionAverageColor</span><span>(</span><span>imageData<span>,</span> rect</span><span>)</span> <span>{</span>
  <span>const</span> lineStride <span>=</span> <span>4</span> <span>*</span> width<span>;</span>
  <span>let</span> r <span>=</span> <span>0</span><span>;</span>
  <span>let</span> g <span>=</span> <span>0</span><span>;</span>
  <span>let</span> b <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>let</span> j <span>=</span> rect<span>.</span>y<span>;</span> j <span>&lt;</span> rect<span>.</span>y <span>+</span> rect<span>.</span>height<span>;</span> j<span>++</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>let</span> i <span>=</span> rect<span>.</span>x<span>;</span> i <span>&lt;</span> rect<span>.</span>x <span>+</span> rect<span>.</span>width<span>;</span> i<span>++</span><span>)</span> <span>{</span>
      r <span>+=</span> imageData<span>[</span>j <span>*</span> lineStride <span>+</span> i <span>*</span> <span>4</span><span>]</span> <span>/</span> <span>0xff</span><span>;</span>
      g <span>+=</span> imageData<span>[</span>j <span>*</span> lineStride <span>+</span> i <span>*</span> <span>4</span> <span>+</span> <span>1</span><span>]</span> <span>/</span> <span>0xff</span><span>;</span>
      b <span>+=</span> imageData<span>[</span>j <span>*</span> lineStride <span>+</span> i <span>*</span> <span>4</span> <span>+</span> <span>2</span><span>]</span> <span>/</span> <span>0xff</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>const</span> count <span>=</span> rect<span>.</span>width <span>*</span> rect<span>.</span>height<span>;</span>
  <span>return</span> <span>{</span>
    <span>r</span><span>:</span> r <span>/</span> count<span>,</span>
    <span>g</span><span>:</span> g <span>/</span> count<span>,</span>
    <span>b</span><span>:</span> b <span>/</span> count
  <span>}</span><span>;</span>
<span>}</span></code></pre><p>Refer to these MDN articles <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Manipulating_video_using_canvas">Manipulating_video_using_canvas</a> and <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/ImageData">ImageData</a> for details about the Web APIs.</p><p>After getting the colors, we can start processing them. First, subtract the top <code>PC1</code> and middle <code>PC2</code> colors, as well as the middle <code>PC2</code> and bottom <code>PC3</code> - like a 1-dimensional convolution. The order of subtraction doesn‚Äôt really matter. This produces two difference colors.</p><p>Let‚Äôs call the resulting colors <code>D1</code> and <code>D2</code>:</p><img srcset="" sizes="" alt="diagram" src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/dimensions_illo3.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><pre><code><span>// To subtract two colors, we subtract each RGB component</span>
<span>const</span> d1 <span>=</span> <span>{</span>
  <span>r</span><span>:</span> pc1<span>.</span>r <span>-</span> pc2<span>.</span>r<span>,</span>
  <span>g</span><span>:</span> pc1<span>.</span>g <span>-</span> pc2<span>.</span>g<span>,</span>
  <span>b</span><span>:</span> pc1<span>.</span>b <span>-</span> pc2<span>.</span>b
<span>}</span><span>;</span>
<span>const</span> d2 <span>=</span> <span>{</span>
  <span>r</span><span>:</span> pc2<span>.</span>r <span>-</span> pc3<span>.</span>r<span>,</span>
  <span>g</span><span>:</span> pc2<span>.</span>g <span>-</span> pc3<span>.</span>g<span>,</span>
  <span>b</span><span>:</span> pc2<span>.</span>b <span>-</span> pc3<span>.</span>b
<span>}</span><span>;</span></code></pre><p>Subtracting two perceived colors eliminates the unknown lighting variable <code>b</code>, as demonstrated in the following derivation:</p><pre><code>D1 = PC2 - PC1
  = (TC2 * a + b) - (TC1 * a + b)
  = TC2 * a - TC1 * a
  = (TC2 - TC1) * a
</code></pre><p>The resulting <code>D1</code> and <code>D2</code> are actually proportional to the true colors. But, they‚Äôre still both influenced by the lighting factor <code>a</code>:</p><pre><code>D1 = (TC2 - TC1) * a
D2 = (TC3 - TC2) * a
</code></pre><p>To remove the remaining lighting variable <code>a</code>, we can "normalize" the values. That is, divide each by the largest value among them.</p><pre><code>N1 = D1 / max(|D1|, |D2|)
N2 = D2 / max(|D1|, |D2|)
</code></pre><p>The resulting values <code>N1</code> and <code>N2</code> represent normalized <code>D1</code> and <code>D2</code> respectively.</p><img srcset="" sizes="" alt="diagram" src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/dimensions_illo4.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><p>And here‚Äôs the code for that:</p><pre><code><span>// Get 'max(|D1|, |D2|)'</span>
<span>const</span> d1Magnitude <span>=</span> Math<span>.</span><span>hypot</span><span>(</span>d1<span>.</span>r<span>,</span> d1<span>.</span>g<span>,</span> d1<span>.</span>b<span>)</span><span>;</span>
<span>const</span> d2Magnitude <span>=</span> Math<span>.</span><span>hypot</span><span>(</span>d2<span>.</span>r<span>,</span> d2<span>.</span>g<span>,</span> d2<span>.</span>b<span>)</span><span>;</span>

<span>// Add 0.001 to avoid division by zero</span>
<span>const</span> max <span>=</span> Math<span>.</span><span>max</span><span>(</span>d1Magnitude<span>,</span> d2Magnitude<span>)</span> <span>+</span> <span>0.001</span><span>;</span>

<span>const</span> n1 <span>=</span> <span>{</span>
  <span>r</span><span>:</span> d1<span>.</span>r <span>/</span> max<span>,</span>
  <span>g</span><span>:</span> d1<span>.</span>g <span>/</span> max<span>,</span>
  <span>b</span><span>:</span> d1<span>.</span>b <span>/</span> max<span>,</span>
<span>}</span><span>;</span>
<span>const</span> n2 <span>=</span> <span>{</span>
  <span>r</span><span>:</span> d2<span>.</span>r <span>/</span> max<span>,</span>
  <span>g</span><span>:</span> d2<span>.</span>g <span>/</span> max<span>,</span>
  <span>b</span><span>:</span> d2<span>.</span>b <span>/</span> max<span>,</span>
<span>}</span><span>;</span></code></pre><p>I‚Äôm not showing the full derivation here, but normalizing will get rid of the common factor <code>a</code>. The handwavy explanation is, if you divide two values having a common factor, that factor gets canceled out.</p><p>Thus, if we expand all the terms:</p><pre><code>N1 = (TC2 - TC1) / max(TC2 - TC1, TC3 - TC2)
N2 = (TC3 - TC2) / max(TC2 - TC1, TC3 - TC2)
</code></pre><p>The result is that the final values <code>N1</code> and <code>N2</code> are derived purely from true color and are not affected by lighting parameters. <small>According to the model anyway.</small></p><p>This whole preprocessing ensures that the algorithm is robust across different lighting conditions and phone cameras, as it only uses true color data.</p><img srcset="" sizes="" alt="" src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/dimensions_tester.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><p>At this point, we can start looking at individual RGB values instead of thinking about "colors". You see, colors are just numbers representing red, green, and blue values.</p><img srcset="" sizes="" alt="" src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/rgb.png" spec="100% [664) 664" loading="lazy" width="" height=""><p>From the normalized colors <code>N1</code> and <code>N2</code>, we can obtain six numerical values (three from each). These values can be rolled into one combined series of numbers, which we‚Äôll call the <strong>feature vector</strong> of the image. The feature vector can be thought of as a numerical representation of certain characteristics of the image.</p><pre><code><span>const</span> featureVector <span>=</span> <span>[</span>
  n1<span>.</span>r<span>,</span>
  n1<span>.</span>g<span>,</span>
  n1<span>.</span>b<span>,</span>
  n2<span>.</span>r<span>,</span>
  n2<span>.</span>g<span>,</span>
  n2<span>.</span>b<span>,</span>
<span>]</span><span>;</span></code></pre><p>In short, the feature vector <em>summarizes</em> the image.</p><img srcset="" sizes="" alt="diagram" src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/dimensions_illo5.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><p>By turning colors into plain numbers, we say goodbye to subjective perceptions of color and enter the objective and computable realm of mathematics.</p><p>This reduces the problem of comparing image similarity into a simple numerical comparison. If the numbers match, then the images match!</p><p>Now, we just need the feature vector of the <em>target image</em> to compare with. We can precompute the same normalization process on the target image and hardcode the resulting feature vector in the app.</p><p>I also got a couple more samples from real photos of the print for good measure.</p><pre><code><span>// (original + real sample 1 + real sample 2) / 3</span>
<span>const</span> targetFeatureVector <span>=</span> <span>[</span>
  <span>(</span>
    <span>-</span><span>0.3593924173784146</span> <span>+</span>
    <span>-</span><span>0.3030924568415693</span> <span>+</span>
    <span>-</span><span>0.27620639981601575</span>
  <span>)</span> <span>/</span> <span>3</span><span>,</span>
  <span>(</span>
    <span>-</span><span>0.611915816235142</span> <span>+</span>
    <span>-</span><span>0.590167832630535</span> <span>+</span>
    <span>-</span><span>0.5946857824325745</span>
  <span>)</span> <span>/</span> <span>3</span><span>,</span>
  <span>(</span>
    <span>-</span><span>0.498629075974555</span> <span>+</span>
    <span>-</span><span>0.4975375806689763</span> <span>+</span>
    <span>-</span><span>0.49879828486061084</span>
  <span>)</span> <span>/</span> <span>3</span><span>,</span>
  <span>(</span>
    <span>0.35716016633879705</span> <span>+</span>
    <span>0.4556467533062926</span> <span>+</span>
    <span>0.47164734468790415</span>
  <span>)</span> <span>/</span> <span>3</span><span>,</span>
  <span>(</span>
    <span>0.17718492626963767</span> <span>+</span>
    <span>0.1053991137797178</span> <span>+</span>
    <span>0.13449453064454686</span>
  <span>)</span> <span>/</span> <span>3</span><span>,</span>
  <span>(</span>
    <span>0.2980055137889341</span> <span>+</span>
    <span>0.30589264583678</span> <span>+</span>
    <span>0.2811110391693084</span>
  <span>)</span> <span>/</span> <span>3</span>
<span>]</span><span>;</span></code></pre><p>Now that we‚Äôve got the feature vectors for both the camera image and target image, we can compare them apples to apples.</p><img srcset="" sizes="" alt="diagram" src="https://leanrada.com/notes/simple-image-recognition-vanilla-js/dimensions_illo6.jpg" spec="100% [664) 664" loading="lazy" width="" height=""><p>We can use Euclidean distance as a measure of vector similarity. Remember, vector similarity is our proxy for image similarity!</p><pre><code><span>const</span> vectorDistance <span>=</span> Math<span>.</span><span>hypot</span><span>(</span>
  <span>...</span>featureVector<span>.</span><span>map</span><span>(</span>
    <span>(</span><span>value<span>,</span> index</span><span>)</span> <span>=&gt;</span>
        targetFeatureVector<span>[</span>index<span>]</span> <span>-</span> value
  <span>)</span>
<span>)</span><span>;</span>

<span>if</span> <span>(</span>vectorDistance <span>&lt;</span> <span>THRESHOLD</span><span>)</span> <span>{</span>
  <span>// Image recognized!</span>
<span>}</span></code></pre><p>If the distance between the two vectors is below a certain threshold, then it‚Äôs a match!</p><p>Voil√†! That‚Äôs the algorithm. You take the input image, turn it into a feature vector, and compare it to a precomputed target vector. The whole image detection code totals less than 200 lines and requires no external library! This algorithm was integrated into the AR app that came along with the art exhibition.</p><p>So, that‚Äôs the image detection algorithm I developed for my AR art app. It‚Äôs pretty straightforward and efficient, with just a few lines of code. It‚Äôs also fast enough to run in real-time on a phone camera feed, which is nice.</p><p>Although it was designed for the specific images I had, you can customize it to suit your needs.</p><p>Now, the algorithm does have a few limitations. It doesn‚Äôt take into account the positioning of the input image, so it has to be in the exact orientation as the target image. Also, extreme lighting conditions, irregular shadows, shiny surfaces, and the like might affect its accuracy.</p><p>Overall, I‚Äôm pretty happy with how it turned out. While it‚Äôs not a general-purpose algorithm, it solved the problem for my art project perfectly. üòÑ</p><p>Want to try out the algorithm? Open this page on a desktop, and then use your phone to scan the QR code in the piece.</p><img srcset="" sizes="" alt="" src="https://leanrada.com/wares/dimensions/media/dimensions_finalset.jpg" spec="100% [800) 80% [1750) 1400" loading="lazy" width="" height=""><p><span>Want to learn more about the art project that this image detection algorithm was a part of? Check out the <a target="_self" href="https://leanrada.com/wares/dimensions">Dimensions project</a>!</span>
                        </p>]]></description>
            <link>https://leanrada.com/notes/simple-image-recognition-vanilla-js</link>
            <guid isPermaLink="true">https://leanrada.com/notes/simple-image-recognition-vanilla-js</guid>
            <pubDate>Fri, 24 Feb 2023 13:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Neural networks √ó genetic algorithms for Pong]]></title>
            <description><![CDATA[<img srcset="" sizes="" alt="screenshot" src="https://leanrada.com/wares/pong-ai/media/pongai1.png" spec="100% [664) 664" loading="lazy" width="" height=""><p><a target="_blank" href="https://en.wikipedia.org/wiki/Neural_network">Neural nets</a> have been around since the 1950s/60s. This Pong AI experiment was done back in 2014, around the time when a revival in neural networks was accelerating, that later brought about the deep learning, modern artificial intelligence that we associate with the term "AI" nowadays.</p><p>The Pong AI here, hovewer, has nothing to do with that deep stuff. I was largely unaware of those new developments in AI back then. This one is a very simple implementation of a 3-layer <a target="_blank" href="https://en.wikipedia.org/wiki/Feedforward_neural_network">feedforward neural network</a>.</p><p>The inputs of the network are ball position, heading, paddle position, etc. and the outputs directly control the paddle.</p><img srcset="" sizes="" alt="network visualization" src="https://leanrada.com/wares/pong-ai/media/net.png" spec="100% [664) 664" loading="lazy" width="" height=""><p>Instead of the usual <a target="_blank" href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>, the learning method I used here was a <a target="_blank" href="https://en.wikipedia.org/wiki/Genetic_algorithm">genetic algorithm</a>. It‚Äôs an evolutionary algorithm that mimics natural selection, reproduction, and mutation to optimize the neural network‚Äôs weights. This was how the Pong "AI" learned.</p><p>To illustrate the learning process, let‚Äôs look at how the AI performs in different stages of learnedness.</p><p>Here‚Äôs an early-generation AI:</p><p><span><em>Note: The AI controls the left paddle. Ignore the right one; it‚Äôs just an automated paddle.</em></span></p><video muted="" autoplay="" loop="" aria-label="video of a generation 2 AI">
                                <source src="https://leanrada.com/wares/pong-ai/media/gen2.mp4">
                                <a href="https://leanrada.com/wares/pong-ai/media/gen2.mp4">video of a generation 2 AI</a>
                            </video><p>As you can see, at this stage, its behaviour is still random with little to no awareness of the ball.</p><p>Sometimes it gets lucky and catches the ball, surviving another volley! This behaviour is rewarded by higher chances of reproduction. The longest surviving AIs in that generation reproduce more to populate the next generation.</p><video muted="" autoplay="" loop="" aria-label="video of a generation 19 AI">
                                <source src="https://leanrada.com/wares/pong-ai/media/gen19.mp4">
                                <a href="https://leanrada.com/wares/pong-ai/media/gen19.mp4">video of a generation 19 AI</a>
                            </video><p>After a few generations, good behaviour emerges while bad behaviour dies out due to natural selection. We can see in generation 19 that it has evolved a behaviour where it tries to follow the ball.</p><p>Now, Pong is a very simple game. If you just follow the ball constantly, you won‚Äôt lose. At about 20 generations the AI has mastered this strategy and is surviving significantly longer. One can conclude that ball-following is the perfect strategy.</p><p>Or is it? ü§î</p><p>What if the ball was faster than the paddle? Then the paddle wouldn‚Äôt be able to keep up and the ball-following strategy will fail.</p><p>And that‚Äôs exactly what I did. I sped up the ball beyond the paddle‚Äôs max speed. Here‚Äôs how the AI adapted:</p><video muted="" autoplay="" loop="" aria-label="video of a generation 54 AI">
                                <source src="https://leanrada.com/wares/pong-ai/media/gen54s.mp4">
                                <a href="https://leanrada.com/wares/pong-ai/media/gen54s.mp4">video of a generation 54 AI</a>
                            </video><p>At generation 54, with a faster ball, the AI has learned to <em>predict</em> the ball!</p><p>It also seems to reposition itself near the middle after every volley as if getting ready for the next shot.</p><p>This was a pretty cool result! I hadn‚Äôt expected this, especially considering how limited / noisy inputs were (in my human eyes, at least).</p><p>Beyond the ball-predicting strategy, I wasn‚Äôt able to discover any more breakthroughs with the AI‚Äôs behaviour. I mean, ball prediction is pretty much the true perfect strategy, regardless of ball speed. At this point I was satisfied with the experiment and moved on to something else.</p><p>Bonus video! Very fast ball, generation 700+:</p><video muted="" autoplay="" loop="" aria-label="video with very fast ball">
                                <source src="https://leanrada.com/wares/pong-ai/media/bv.mp4">
                                <a href="https://leanrada.com/wares/pong-ai/media/bv.mp4">video with very fast ball</a>
                            </video>]]></description>
            <link>https://leanrada.com/wares/pong-ai</link>
            <guid isPermaLink="true">https://leanrada.com/wares/pong-ai</guid>
            <pubDate>Fri, 17 Feb 2023 13:00:00 GMT</pubDate>
        </item>
    </channel>
</rss>