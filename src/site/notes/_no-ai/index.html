<html lang="en">
  <page-title title="AI art is not generative art" />
  <blog-page path-group="/notes/">
    <content-header slot="precontent" title="AI art is not generative art" />
    <blog-post-info date="18 Nov 2023" hidden />
    <!-- textlint-disable -->
    <tag-row>
      <tag>essay</tag>
    </tag-row>
    <!-- textlint-enable -->
    <!-- prettier-ignore -->
    <markdown>
      *AI art* is not *generative art* (clickbait title). OK, while the technical definition says that one is a subset of the other, I think it’s useful to distinguish between these two categories.

      **Why I’m writing this in the first place &mdash;** Starting 2022, the term “generative art” has been progressively becoming synonymous with art produced by AI text-to-image systems. As a consumer and producer of “generative art”, it’s becoming a bit annoying to browse generative art content on the internet. Whether through tags like `#generativeart` or communities like `r/generative`, they are being flooded with AI-generated images which I’m not interested in. End rant.

      At this point you may be asking, what’s the difference anyway? Well, that’s the point of this essay. It’s kinda like animals vs humans. While technically & scientifically, humans are animals; in daily life “animals” usually mean non-human animals, as in “animal lover” and “animal rights”. Imagine browsing `r/AnimalsBeingGeniuses` then seeing only humans doing mundane things like reading or writing. I digress. Let’s look at the differences in different angles, starting with _lineages_.

      ## Lineages

      Tracing the history of each practice may offer some insights and nuance.

      <div class="timeline-entry timeline-entry-ai">
        <div class="timeline-bullet">1943</div>
        <card class="timeline-card">
          The first artificial neural networks were proposed by neuroscientists <text-link href="https://en.wikipedia.org/wiki/Warren_Sturgis_McCulloch#Neural_network_modelling">Warren McCulloch</text-link> and <text-link href="https://en.wikipedia.org/wiki/Walter_Pitts">Walter Pitts</text-link>. These were abstract machines modeled after biological neurons (brain cells). Early neural networks were unable to learn; their internal connections were fixed.
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-ai">
        <div class="timeline-bullet">1958</div>
        <card class="timeline-card">
          <p><text-link href="https://en.wikipedia.org/wiki/Frank_Rosenblatt">Frank Rosenblatt</text-link> built a neural network that can be trained, called the <strong>perceptron</strong>.</p>
          <p>It learns through <strong>examples</strong>. By going through a number of examples, the network can be iteratively corrected to better <em>model</em> the general idea across the examples and generalise beyond the training dataset. This concept of learning by example has been the standard for learning machines since then.</p>
          <p><em style="opacity:0.6">Following the hype of the perceptron and its shortcomings is a long AI Winter(s).</em></p>
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-gen">
        <div class="timeline-bullet">~1969</div>
        <card class="timeline-card">
          Around 1970, artist <text-link href="https://en.wikipedia.org/wiki/Sol_LeWitt#Wall_drawings">Sol LeWitt</text-link> started doing something called wall drawings, sets of instructions that produce abstract drawings. These can be thought of as precursors to generative art.
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-gen">
        <blog-media :src="url('lewitt.jpg')" caption="Product of Wall Drawing #797, executed from instructions written by LeWitt." />
      </div>
  
      <div class="timeline-entry timeline-entry-gen">
        <card class="timeline-card">
          Sol LeWitt referred to this kind of art as <strong>conceptual art</strong>. "The idea becomes a machine that makes the art." (Paragraphs on Conceptual Art, 1967) It's not quite generative art because the instructions are executed by humans, but it's close.
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-gen">
        <div class="timeline-bullet">1968</div>
        <card class="timeline-card">
          <p>In 1968, <text-link href="https://en.wikipedia.org/wiki/Vera_Moln%C3%A1r">Vera Molnár</text-link> brought us closer to modern generative art by actually using computers and writing code to generate artworks.</p>
          <p style="opacity:0.6"><em>Yeah I know the timeline order is messed up, but the story makes more sense in this order.</em></p>
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-gen">
        <blog-media :src="url('molnar.jpg')" caption="Vera Molnár" />
      </div>
    
      <div class="timeline-entry timeline-entry-gen">
        <div class="timeline-bullet">1998</div>
        <card class="timeline-card">
          <p>Since 1998, artists began meeting in generative art conferences and the artistic community started converging on a shared definition of generative art.</p>
          <blockquote><i>Generative art has been defined as work that has been produced by the execution, usually by a computer system, of a set of rules or procedures determined by the artist.</i></blockquote>
        </card>
      </div>
      
      <div class="timeline-entry timeline-entry-ai">
        <div class="timeline-bullet">2015</div>
        <card class="timeline-card">
          <p>Deep learning revolution. Someone figured out how to use the increased computing power to train bigger and better neural networks. It turns out more neurons is better.</p>
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-ai">
        <div class="timeline-bullet">2015</div>
        <card class="timeline-card">
          <p>Advances in generative models for deep neural networks.</p>
          <p>Before, deep neural networks were mostly discriminative models.</p>
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-ai">
        <div class="timeline-bullet">2015</div>
        <card class="timeline-card">
          <p>The first modern <strong>text-to-image model</strong> was introduced.</p>
          <p>Text-to-image models are systems that use deep neural networks to generate images from natural language descriptions.</p>
          <p>It was called <strong>alignDRAW</strong>.</p>
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-ai">
        <div class="timeline-bullet">2021</div>
        <card class="timeline-card">
          <p><strong>DALL·E</strong> was revealed by OpenAI. Another text-to-image model, one that caught the public eye.</p>
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-gen">
        <div class="timeline-bullet">2022</div>
        <card class="timeline-card">
          <p>2022 saw the rise and fall of NFTs, which have been associated with generative art.</p>
          <p>Honestly, some of them are of the shallow kind of generative art, Mad Libs-style images generated from shufflings of pre-drawn hairstyles, sunglasses, and clothes.</p>
        </card>
      </div>
      
      <div class="timeline-entry timeline-entry-gen">
        <blog-media :src="url('apes.png')" caption="Typical images associated with NFTs" />
      </div>
  
      <div class="timeline-entry timeline-entry-ai">
        <div class="timeline-bullet">2022</div>
        <card class="timeline-card">
          <p>Text-to-image models were approaching the quality of real images like photographs. People were using these image generators to generate artworks that approach the quality of human art.</p>
          <p style="opacity:0.6">Note: These are text-to-<em>image</em> models, not just text-to-<em>art</em> models. It just happened that artworks are images too. All kinds of images &mdash; photographs, screenshots, diagrams, book scans, floor plans, and yes, artworks &mdash; were in the training datasets.</p>
        </card>
      </div>
  
      <div class="timeline-entry timeline-entry-gen">
        <div class="timeline-bullet">now</div>
        <card class="timeline-card">
          <p>Today we see different tools to make generative art, from none (straight up coding), to frameworks like p5.js, to full-blown authoring software like TouchDesigner.</p>
        </card>
      </div>
  
      Craft
      * Skills
      * Math
      * 
    </markdown>
  </blog-page>
</html>

<style>
  .timeline-entry {
    position: relative;
    margin: 48px 0;
  }
  .timeline-card > :first-child {
    margin-top: 0;
  }
  .timeline-card > :last-child {
    margin-bottom: 0;
  }
  .timeline-bullet {
    display: flex;
    flex-direction: column;
    align-items: center;
  }
  .timeline-bullet::after {
    content: "";
    display: block;
    width: 12px;
    height: 12px;
    border-radius: 12px;
    background: white;
  }
  @media (min-width: 1400px) {
    .timeline-entry-gen {
      right: calc(50% + 72px / 2);
    }
    .timeline-entry-ai {
      left: calc(50% + 72px / 2);
    }
    .timeline-bullet {
      position: absolute;
      width: 72px;
    }
    .timeline-entry-gen .timeline-bullet {
      left: 100%;
    }
    .timeline-entry-ai .timeline-bullet {
      right: 100%;
    }
  }
</style>
