<html lang="en">
  <page-title title="AI art is not generative art" />
  <blog-page path-group="/notes/">
    <content-header slot="precontent" title="AI art is not generative art" />
    <blog-post-info date="18 Nov 2023" hidden />
    <!-- textlint-disable -->
    <tag-row>
      <tag>essay</tag>
    </tag-row>
    <!-- textlint-enable -->
    <!-- prettier-ignore -->
    <markdown>
      **AI art is not _generative art_** (clickbait title). While the technical definition says that one is a subset of the other, I think it’s useful to distinguish between these two categories.

      **Why I’m writing this in the first place &mdash;** Starting 2022, the term “generative art” had been progressively becoming synonymous with art produced by AI text-to-image systems. As a consumer and producer of (traditional) generative art, it was becoming a bit annoying to browse generative art content on the internet. Whether through tags like `#generativeart` or communities like `r/generative`, spaces are being flooded with AI-generated images which I and many others are not interested in. End rant.

      <box-note>In 2024, things are a bit different. AI art is now commonly referred to as ‘AI art’. I shouldn’t have procrastinated writing this essay for so long.</box-note>

      At this point you may be asking, what’s the difference anyway? Well, that’s the point of this post. It’s kinda like animals vs humans. While technically & scientifically, humans are (a subset of) animals; in daily life “animals” usually mean non-human animals, as in “animal lover” and “animal rights”. I digress.
      
      ## Section overview

      This article looks at the similarities and differences between (traditional) generative art and text-to-image AI art in <span style="display:inline-block;transform:rotate(-3deg)">different</span> <span style="display:inline-block;transform:rotate(27deg)">angles</span>. Skip to different sections if you want.

      1. [History](#history)
      2. [Craft](#the-craft)
      3. [Process](#the-process)

      ## History

      Tracing the history of each practice may offer insights and nuance. Don’t worry, there are pictures! ~~And interactive things!~~ <small>(too lazy to implement interactive things for now)</small>
      
      <span style="opacity: 0.7">This is not a comprehensive history of either field. The dates are probably off by a couple years. Btw, this timeline layout is better viewed on a large screen.</span>

      <div class="timeline">
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">1940s</div>
          <card class="timeline-card">
            The first artificial neural networks were proposed; abstract machines modeled after biological neurons (brain cells).
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <blog-media :src="url('neurons.png')" alt="Diagrams of a human neuron and an artificial neuron" />
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">1950s</div>
          <card class="timeline-card">
            <h3>The Perceptron</h3>
            <p><text-link href="https://en.wikipedia.org/wiki/Frank_Rosenblatt">Frank Rosenblatt</text-link> built a relatively simple neural network that can be trained, called the <em>perceptron</em>.</p>
            <p>The perceptron was designed for image recognition. The perceptron looks at some input (an image) and decides from a set of pre-learned classes of images, which kind of image it is.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">1960s</div>
          <card class="timeline-card">
            <h3>Conceptual art</h3>
            <p>Artist <text-link href="https://en.wikipedia.org/wiki/Sol_LeWitt#Wall_drawings">Sol LeWitt</text-link> started doing something called wall drawings, sets of instructions that produce abstract drawings. These can be thought of as precursors to generative art.</p>
            <blockquote>“<strong>Wall Drawing #797.</strong> <i>The first drafter has a black marker and makes an irregular horizontal line near the top of the wall. Then the second drafter tries to copy it (without touching it) using a red marker. The third drafter does the same, using a yellow marker. The fourth drafter does the same using a blue marker. Then the second drafter followed by the third and fourth copies the last line drawn until the bottom of the wall is reached.</i>”</blockquote>
            <!-- todo: popout interactive -->
            <blog-media :src="url('lewitt.jpg')" alt="Picture of Wall Drawing #797" caption="Product of Wall Drawing #797, executed from instructions written by LeWitt." />
            <p>"The idea becomes a machine that makes the art." (Paragraphs on Conceptual Art, 1967) It's not quite <em>generative art</em> but it’s close. Besides, LeWitt called it something else: <strong>“conceptual art”</strong>.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">1960s</div>
          <card class="timeline-card">
            <h3>Code art</h3>
            <text-link href="https://en.wikipedia.org/wiki/Vera_Moln%C3%A1r">Vera Molnár</text-link> brought us closer to modern generative art by actually using computers and writing code to generate artworks.</p>
            <!-- todo: popout interactive -->
            <blog-media :src="url('molnar.jpg')" alt="Picture of art of Vera Molnár" caption="Vera Molnár" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">1970s</div>
          <card class="timeline-card">
            <h3>AI winter ⛄</h3>
            <p>The limitations of relatively primitive AI and weak computing power back then resulted in massive disappointment about AI. Budgets were cut. R&D slowed down. Hype was lost.</p>          
            <p>The Perceptron did not achieve self-awareness.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">1990s</div>
          <card class="timeline-card">
            <p>Since 1990s, artists began meeting in generative art conferences and the artistic community started converging on a shared definition of generative art.</p>
            <blockquote><strong>Generative art &mdash;</strong> work that has been produced by the execution, usually by a computer system, of a set of rules or procedures determined by the artist.</blockquote>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2010s</div>
          <card class="timeline-card">
            <h3>Deep learning</h3>
            <p>The intersection of advancements in computing power, improved machine learning algorithms, and huge ever-growing datasets of digital things resulted in bigger and better neural networks. The great potential of AI was reignited. The start of the <strong>deep learning revolution</strong>.</p>
            <p>Image recognition, picture captioning, automated language translation, text-to-speech, speech-to-text, etc. got seriously buffed.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <blog-media :src="url('deepdream.jpg')" alt="Picture of DeepDream output" caption="Google’s DeepDream exploits image recognition feeding into digital pareidolia. It can be considered early AI art, but it’s quite different from modern AI art." />
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <card class="timeline-card">
            <h3>Generative networks</h3>
            <p>Due to deep learning, we had advancements in generative networks, which are networks that can generate new data on their own instead of simply being a complex input-output mapping.</p>
            <p>This seems to be the start of the <strong>image synthesis</strong> wave.</p>
            <p>
              <!-- todo: interactive (just cycle through prerendereds) -->
              <responsive-img class="thisperson" alt="Portrait of a person" :src="url('thisperson.jpg')" spec="100" /> Here is a fake person generated by <text-link href="https://www.thispersondoesnotexist.com/">a generative adversarial network (GAN) trained specifically on portraits</text-link>.
            </p>
            <div style="clear:left"></div>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2015</div>
          <card class="timeline-card">
            <h3>Text to image</h3>
            <p>The first modern text-to-image model was introduced.</p>
            <p>It was called <strong>alignDRAW</strong>.</p>
            <p>It can generate images from <em>natural language descriptions</em>, making these machines massively accessible as the general public could simply type in what they wanted to see.</p>
            <blog-media :src="url('aligndraw.jpg')" alt="8 blurry images of a white blob on a green background" caption="alignDRAW’s output for “A toilet seat sits open in
            the grass field.”" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2021</div>
          <card class="timeline-card">
            <p><strong><text-link href="https://en.wikipedia.org/wiki/DALL-E">DALL·E</a></strong> was revealed by OpenAI. Another text-to-image model, and it became famous. (Or, rather it was made famous by “DALL-E mini” which was <em>viral</em>.)</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('dalle.png')" alt="Image of a toilet seat in a field" caption="DALL·E’s output for “A toilet seat sits open in the grass field.”" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">2022</div>
          <card class="timeline-card">
            <p>Meanwhile, 2022 saw a burst of NFTs, most of which have been associated with generative art.</p>
            <p>Honestly, some of them are on the borderline shallow end of generative art, Mad Libs-style images generated from shufflings of pre-drawn hairstyles, sunglasses, and clothes. They are more akin to the <text-link href="https://en.wikipedia.org/wiki/Musikalisches_W%C3%BCrfelspiel">musical dice game</text-link>.</p>
            <blog-media :src="url('apes.png')" alt="Images resembling the Bored Apes collection of images" caption="Typical images associated with NFTs" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2022</div>
          <card class="timeline-card">
            <p>Text-to-image models were approaching the quality of real images such as photographs. People were using these image generators to generate artworks that approach the quality of human art.</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('house.png')" alt="Image of a painting of a house" caption="AI-generated painting" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">2020s</div>
          <card class="timeline-card">
            <p>Today, we see different techniques and tools to make generative art, from straight up canvas coding, to frameworks like <text-link href="https://p5js.org/">p5.js</text-link>, to full-blown authoring software like <text-link href="https://derivative.ca/">TouchDesigner</text-link> and <text-link href="https://www.sidefx.com/">Houdini</text-link>.</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('qql.jpg')" alt="Abstract art composed of many non-overlapping small circles" caption="An output of the QQL algorithm which uses the p5.js library" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2020s</div>
          <card class="timeline-card">
            <p>Tools to make AI art and images have been heavily commercialised, with online image generation services provided by OpenAI/Microsoft, Google, and Midjourney. There are also local models for advanced users and tinkerers.</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('midjournee.png')" alt="Screenshot of an online image generator" caption="Microsoft’s image creator which at the time used the DALL·E 3 model" />
          </card>
        </div>
      </div>

      So. AI art is a relatively new movement borne out of general image synthesizers. This was made possible since visual artworks are images too. Meanwhile, there have been decades of development and refinement in (traditional) generative art, techniques, and algorithms.
      
      The terminology may overlap (generative networks ~ generative art), but these are just labels. You may call them whatever you want, but they’re still <strong>separate art movements that cannot be historically reconciled</strong>.

      <box-note>By the way, I don’t care if you want to call them ‘art’ or not. That’s not the point of this essay. If it bothers you, please imagine that all instances of the word ‘art’ were replaced with ‘image’. Same for the word ‘artist’.</box-note>

      ## The craft

      OK so, whatever sure, history is in the past. Why don’t we look at it in terms of what artists are doing today. What do they do? What do they practise to improve?

      ### Unique skills

      Both practices involve some unique skills that are not in common with the other. They each have their own defining skills.

      <div class="horizontal-scroll">
        <table class="venn-table">
          <tr>
            <th>Generative artists</th>
            <th>AI artists</th>
          </tr>
          <tr>
            <td class="venn venn-gen">
              programming<br>
              math / geometry / trigonometry<br>
            </td>
            <td class="venn venn-ai">
              prompting<br>
              curation / training<br>
              describing<br>
            </td>
          </tr>
        </table>
      </div>
      <style>
        .venn-table {
          margin: auto;
          padding: 10% 0;
          width: 420px;
          table-layout: fixed;
          text-align: center;
        }
        .venn-table th {
          padding-bottom: 24px;
        }
        .venn {
          position: relative;
        }
        .venn::before {
          content: "";
          position: absolute;
          inset: -20% -10%;
          border-radius: 50%;
          mix-blend-mode: color-dodge;
          z-index: -1;
        }
        .venn-ai::before {
          right: 0;
          background-color: var(--ai-clr-dark);
        }
        .venn-gen::before {
          left: 0;
          background-color: var(--gen-clr-dark);
        }
        .venn-intersection {
          width: 0;
        }
        .venn-intersection-content {
          width: fit-content;
          transform: translate(-50%);
        }
      </style>

      **Generative art** involves programming and uses math (usually geometry or trigonometry) to create graphics. A good undertanding of functions and their domains and ranges and how they compose together is essential, especially when taming random number generators.
      
      <blog-media :src="url('math.png')" caption="Typical generative art math" />

      Beyond these core skills, there are a lot of areas generative artists could expand into, like graph theory, simulations, fractals, image processing, and other advanced algorithms.

      <blog-media :src="url('pathways.png')"><span slot="caption">
        <text-link href="https://www.fxhash.xyz/generative/slug/scattered-pathways" target="_blank">Scattered Pathways</text-link>  by Nate Nolting.<br>Generative art using a graph pathfinding algorithm
      </span></blog-media>

      **AI art**, on the other hand, is heavy on prompt engineering. It could be as simple as writing English descriptions, or as precise as inputting parameterised labels if the tool allows for it.
      
      <card>
        <b><u>Prompt:</u></b> Dog, (Artist Name, Artist Name), Masterpiece, Studio Quality, 6k, glowing, axe, mecha, science_fiction, solo, weapon, jungle, green_background, nature, outdoors, solo, tree, weapon, mask, dynamic lighting, detailed shading, digital texture painting
        <br><b><u>Negative prompt:</u></b> un-detailed skin, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, ugly eyes, (out of frame:1.3), worst quality, low quality, jpeg artifacts, cgi, sketch, cartoon, drawing, (out of frame:1.1)
        <br><b><u>Parameters:</u></b> Steps: 50, Sampler: Euler a, CFG scale: 7.0, Seed: 1579799523, Face restoration, Size: 512x512
      </card>
      <span class="caption">Example prompt with advanced parameters (e.g. for StableDiffusion)</span>

      Beyond writing prompts, there are several tools that allow more control like influencing certain compositional elements. AI artists could also train or fine-tune models by curating image-label datasets as extra training data.

      <blog-media :src="url('control.png')"><span slot="caption">
        Images generated with <text-link href="https://github.com/lllyasviel/ControlNet" target="_blank">ControlNet</text-link>, controlling the general shape of the subject.
      </span></blog-media>

      There seems to be little to no transferable skills between these practices. Sure, you can program some scripts to automate parts of an AI art workflow, or add an AI filter step to an otherwise procedurally-generated image. But for the most part, there is no necessary overlap.
      
      That’s why you can’t just ask an AI artist to please create an interactive audio-reactive visualisation for your music video, but a generative artist could. Likewise, you can’t expect a generative artist to easily generate photorealistic art but an AI artist can in seconds.

      ### Skills in common

      One big thing that’s common between these practices is the need to curate. Since both involve chaos and randomness, a curation step is almost always required before finishing a work. Curation requires artistic vision, which is a skill.
      
      <div class="horizontal-scroll">
        <table class="venn-table" aria-label="Venn-diagram showing curation & artistic vision in the intersection between Generative artists and AI artists">
          <tr>
            <td class="venn venn-gen" style="padding-inline-end: 10%">
              <b>Generative<br>artists</b>
            </td>
            <td class="venn-intersection">
              <div class="venn-intersection-content">
                curation<br>
                artistic vision
              </div>
            </td>
            <td class="venn venn-ai" style="padding-inline-start: 10%">
              <b>AI<br>artists</b>
            </td>
          </tr>
        </table>
      </div>

      **What’s curation?** As you finish a piece, you’d usually want to generate multiple outputs, not just one. Then you’d select the best one(s) to publish. That’s curation. This happens in either practice. Alternatively, you might refine and iterate your prompt / program until the generated outputs satisfy your artistic vision.
      
      <blog-media :src="url('uncurated.png')" caption="Uncurated set of outputs from a generative art algorithm" />

      <blog-media :src="url('ai-outputs.png')" caption="AI image generators usually generate multiple outputs at a time for you to curate." />

      It could be argued that having artistic vision and doing iterations are pretty common to all arts, and so those alone don’t make generative art and AI art any more similar to each other than any other art.

      <box-note>**Disclaimer:** I’m not very good at AI image generation. I don’t have first-hand experience of the advanced skills that I mentioned like fancy prompt engineering or fine-tuning. (Though I did train a different type of <text-link href="/wares/pong-ai/" target="_blank">neural network</text-link> before). In any case, I attempted to reduce my bias and subjectivity.</box-note>

      Overall, the significant differences in skillsets mean that **generative artists and AI artists are not interchangeable**, and the same should go for their respective arts.

      ## The process

      Finally, let’s attack the subject from the POV of processes and systems.

      Setting aside the question of whether Art is Product or Process, let us indulge in these animations of art in the process of being products.

      <div
        class="horizontal-scroll"
        style="
          display: grid;
          place-content: center;
          grid-template-columns: repeat(2, minmax(min(80vw, 320px), min-content));
          gap: 18px"
      >
        <blog-media
          :src="url('diffusion.mp4')"
          caption="AI art being formed via denoising" />
        <blog-media
          :src="url('flowers.mp4')"
          caption="Generative art being formed via programmed strokes" />
      </div>

      Recent AI image generators form images via **denoising**. The animation above (left) shows the sequence of steps taken by the generator to progressively denoise a pure noise image into something coherent based on a prompt.

      Generative art algorithms, on the other hand, are relatively hand-crafted with specific instructions to draw every element in the piece. This is very apparent in the above animation (right) where each stroke is individually drawn according to the artist’s rules. (animation from <text-link href="https://www.fxhash.xyz/generative/slug/the-soul-of-flowers">The Soul of Flowers</text-link> by Che-Yu Wu)
 
      ### System diagrams

      Beyond the processes themselves, art interacts with the context of its creation. And, whew, there is a lot to unpack here, especially for AI art. I’ll use diagrams to illustrate the context of the creation process.

      **In the process of generative art,** there are three components at the least: the artist, the program, and the rendered output.

      <blog-media :src="url('gen-system.png')" type="bleed" caption="System diagram of generative art" />

      The artist writes the program that renders the piece of art.
      
      They may use libraries or frameworks as part of the program, but the artist ultimately specifies the steps or rules which the program would execute at a certain level of abstraction.
      
      The artist has full control over how the program would render the art. In fact, it’s impossible to not have full control because programming is precise. You have to artificially create *whim* (i.e. randomness) to produce dynamic results.

      **In the process of AI art,** there are four components at the minimum: the artist, the model, the rendered output, and *the dataset*.

      <blog-media :src="url('ai-system.png')" type="bleed" caption="System diagram of AI art" />

      The artist prompts the model trained from the dataset to produce the piece of art.

      Comparing the generative art process with the AI art process, there is an immediate difference. Unlike AI art, **generative art don’t need datasets**.
      
      And it’s the controversial thing, the dataset. The data used to train a text-to-image model can consist of billions of images, usually scraped from the Internet and includes other artworks by other artists.

      If you consider that the model has been influenced by a lot of other artists (and whole lot more of other random images on the web), then the question of how important the AI artist’s influence over the final piece is raised. *Was that chiaroscuro an artistic choice, or an emergent byproduct of the model? Was the rule of thirds intentional, or just some typical composition produced by the model?*
      
      Unlike AI art, there is no confusion in generative art over who worked out the art of the artwork.

      Leaving the contentious topic aside, generative artists also have more control over the render, while AI art is constrained to a more vague level of influence. There’s always an unavoidable level of indirection in the AI art process. A black box.
      
      On an opposite note, AI artists can be thought of as high-level artistic directors who don’t concern themselves with the rendering of mid- to low-level strokes and details. Generative artists must always specify the exact procedure for both the broad strokes and the fine details.

      ## Conclusion

      The point is that these are separate _art mediums_. Or _art movements_, if you will. The histories, the crafts, and the processes point to the same conclusion &mdash; they are no more similar than oil painting is to photography, or a film director to an animator.

      On naming &mdash; Actually, AI art is mostly being called ‘AI art’ nowadays. When I started writing this essay, there was a bit of uncertainty as people came up with new names for this new thing. Now, some aspects of the essay have probably been outdated. I’ll still include them in the post because why not. The stand may be pointless, but the point still stands.
    </markdown>
  </blog-page>
</html>

<style>
  :root { 
    --ai-clr-dark: #5a2a87;
    --gen-clr-dark: #325300;
  }
  .thisperson {
    float: left;
    shape-outside: circle();
    margin-right: 18px;
    width: 100px;
    height: 100px;
    border-radius: 50%;
  }

  .timeline {
    background: linear-gradient(
      to right,
      transparent calc(50% - 0.5px),
      var(--card-clr) calc(50% - 0.5px),
      var(--card-clr) calc(50% + 0.5px),
      transparent calc(50% + 0.5px)
    );
  }

  .timeline-entry {
    position: relative;
    margin: 12px 0;
  }
  .timeline-card > :first-child {
    margin-top: 0;
  }
  .timeline-card > :last-child {
    margin-bottom: 0;
  }
  .timeline-card h3 {
    font-size: 18px;
    font-family: var(--display-font);
    font-style: italic;
    font-weight: bold;
    text-align: center;
  }
  .timeline-entry-gen .timeline-card {
    border-color: var(--gen-clr-dark);
  }
  .timeline-entry-ai .timeline-card {
    border-color: var(--ai-clr-dark);
  }

  .timeline-bullet {
    display: flex;
    flex-direction: column;
    align-items: center;
    margin-bottom: 12px;
  }
  .timeline-bullet::after {
    content: "";
    display: block;
    width: 12px;
    height: 12px;
    border-radius: 12px;
    background: white;
  }

  @media (min-width: 1400px) {
    .timeline-entry-gen {
      right: calc(50% + 72px / 2);
    }
    .timeline-entry-ai {
      left: calc(50% + 72px / 2);
    }
    .timeline-entry-gen + .timeline-entry-ai,
    .timeline-entry-ai + .timeline-entry-gen {
      margin-top: -72px;
    }
    .timeline-bullet {
      position: absolute;
      width: 72px;
    }
    .timeline-entry-gen .timeline-bullet {
      left: 100%;
    }
    .timeline-entry-ai .timeline-bullet {
      right: 100%;
    }
  }
</style>
