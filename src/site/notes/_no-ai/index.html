<html lang="en">
  <page-title title="AI art is not generative art" />
  <blog-page path-group="/notes/">
    <content-header slot="precontent" title="AI art is not generative art" />
    <blog-post-info date="18 Nov 2023" hidden />
    <!-- textlint-disable -->
    <tag-row>
      <tag>essay</tag>
    </tag-row>
    <!-- textlint-enable -->
    <!-- prettier-ignore -->
    <markdown>
      **AI art is not _generative art_** (clickbait title). While the technical definition says that one is a subset of the other, I think it’s useful to distinguish between these two categories.

      **Why I’m writing this in the first place &mdash;** Starting 2022, the term “generative art” has been progressively becoming synonymous with art produced by AI text-to-image systems. As a consumer and producer of “generative art”, it’s becoming a bit annoying to browse generative art content on the internet. Whether through tags like `#generativeart` or communities like `r/generative`, they are being flooded with AI-generated images which I’m not interested in. End rant.

      At this point you may be asking, what’s the difference anyway? Well, that’s the point of this post. It’s kinda like animals vs humans. While technically & scientifically, humans are animals; in daily life “animals” usually mean non-human animals, as in “animal lover” and “animal rights”. Imagine browsing `r/AnimalsBeingGeniuses` then seeing only humans doing mundane things like reading or writing. I digress.
      
      Let’s look at the differences in different angles.

      1. History
      2. Craft
      3. Process

      ## History

      Tracing the history of each practice may offer some insights and nuance.

      <div class="timeline">
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">1943</div>
          <card class="timeline-card">
            The first artificial neural networks were proposed; abstract machines modeled after biological neurons (brain cells).
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">1958</div>
          <card class="timeline-card">
            <p><text-link href="https://en.wikipedia.org/wiki/Frank_Rosenblatt">Frank Rosenblatt</text-link> built a relatively simple neural network that can be trained, called the <strong>perceptron</strong>.</p>
            <p>It can trained through <strong>examples</strong>. This idea of learning by example has been the standard for learning machines up to now.</p>
            <p><em style="opacity:0.6">Following the hype of the perceptron and its shortcomings (it was too simple) is the long AI Winter(s).</em></p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">1969</div>
          <card class="timeline-card">
            <p>Artist <text-link href="https://en.wikipedia.org/wiki/Sol_LeWitt#Wall_drawings">Sol LeWitt</text-link> started doing something called wall drawings, sets of instructions that produce abstract drawings. These can be thought of as precursors to generative art.</p>
            <!-- todo: popout interactive -->
            <blog-media :src="url('lewitt.jpg')" caption="Product of Wall Drawing #797, executed from instructions written by LeWitt." />
            <p>"The idea becomes a machine that makes the art." (Paragraphs on Conceptual Art, 1967) It's not quite <em>generative art</em> yet but it's close. Besides, LeWitt called it something else: <strong>“conceptual art”</strong>.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">1968</div>
          <card class="timeline-card">
            <text-link href="https://en.wikipedia.org/wiki/Vera_Moln%C3%A1r">Vera Molnár</text-link> brought us closer to modern generative art by actually using computers and writing code to generate artworks.</p>
            <!-- todo: popout interactive -->
            <blog-media :src="url('molnar.jpg')" caption="Vera Molnár" />
            <p style="opacity:0.6"><em>Yeah I know the timeline order is messed up, but the story makes more sense in this order.</em></p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">1998</div>
          <card class="timeline-card">
            <p>Since 1998, artists began meeting in generative art conferences and the artistic community started converging on a shared definition of generative art.</p>
            <blockquote><strong>Generative art &mdash;</strong> work that has been produced by the execution, usually by a computer system, of a set of rules or procedures determined by the artist.</blockquote>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2013</div>
          <card class="timeline-card">
            <p><strong>Deep learning revolution</strong>: The intersection of advancements in computing power, improved machine learning algorithms, and huge ever-growing datasets of digital things resulted in bigger and better neural networks. The great potential of machine learning and AI was reignited.</p>
            <p>Image recognition, picture captioning, language translation, text-to-speech, etc. got seriously buffed.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <card class="timeline-card">
            <p>Advancements in <strong>generative networks</strong> due to deep learning. (Generative networks are networks that can generate new data on their own instead of simply an input-output mapping.)</p>
            <p>This seems to be the start of the <strong>image synthesis</strong> wave.</p>
            <p>
              <!-- todo: interactive (just cycle through prerendereds) -->
              <responsive-img class="thisperson" :src="url('thisperson.jpg')" spec="100" /> Here is a fake person generated by a generative adversarial network (GAN) trained on portraits.
            </p>
            <div style="clear:left"></div>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2015</div>
          <card class="timeline-card">
            <p>The first modern <strong>text-to-image model</strong> was introduced.</p>
            <p>Text-to-image models are systems that use deep neural networks to generate images from natural language descriptions.</p>
            <p>It was called <strong>alignDRAW</strong>.</p>
            <blog-media :src="url('aligndraw.jpg')" caption="alignDRAW’s output for “A toilet seat sits open in
            the grass field.”" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2021</div>
          <card class="timeline-card">
            <p><strong>DALL·E</strong> was revealed by OpenAI. Another text-to-image model, and it caught the public eye.</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('dalle.png')" caption="DALL·E’s output for “A toilet seat sits open in
            the grass field.”" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">2022</div>
          <card class="timeline-card">
            <p>Meanwhile, 2022 saw the burst of NFTs, most of which have been associated with generative art.</p>
            <p>Honestly, some of them are on the borderline shallow end of generative art, Mad Libs-style images generated from shufflings of pre-drawn hairstyles, sunglasses, and clothes. They are more akin to the <text-link href="https://en.wikipedia.org/wiki/Musikalisches_W%C3%BCrfelspiel">musical dice game</text-link>.</p>
            <blog-media :src="url('apes.png')" caption="Typical images associated with NFTs" />
            <p>Just like AI art or any other art for that matter, the quality and effort of every work can vary.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2022</div>
          <card class="timeline-card">
            <p>Text-to-image models were approaching the quality of real images such as photographs. People were using these image generators to generate artworks that approach the quality of human art.</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('house.png')" caption="AI-generated painting" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">2024</div>
          <card class="timeline-card">
            <!-- todo how about make timeline entries for each of these tools (when were they created?) -->
            <p>Today we see different tools to make generative art, from none (straight up coding), to frameworks like p5.js, to full-blown authoring software like TouchDesigner and Houdini.</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('qql.jpg')" caption="An output of the QQL algorithm which uses the p5.js library" />
          </card>
        </div>
      </div>
  
      ## Craft

      Let’s look at it in terms of the skills involved for the artists.

      * Skills
      * Math
      * Code

      <!-- todo show animation of generative being drawn -->

      ## Processes and systems

      Let’s look at it from a systems and processes POV.

      process diagrams

        artist -> program -> autonomous render -> art
        
        dataset (big box) -> ML -> AI -.
        artist -> prompt -> AI -> digital art

      ## Conclusion

      To be fair, AI art is mostly being called AI art nowadays.

      My point is these are different _art movements_.
    </markdown>
  </blog-page>
</html>

<style>
  .thisperson {
    float: left;
    margin-right: 18px;
    width: 100px;
    height: 100px;
    border-radius: 50%;
  }

  .timeline {
    background: linear-gradient(
      to right,
      transparent calc(50% - 0.5px),
      var(--card-clr) calc(50% - 0.5px),
      var(--card-clr) calc(50% + 0.5px),
      transparent calc(50% + 0.5px)
    );
  }
  .timeline-entry {
    position: relative;
    margin: 12px 0;
  }
  .timeline-card > :first-child {
    margin-top: 0;
  }
  .timeline-card > :last-child {
    margin-bottom: 0;
  }
  .timeline-bullet {
    display: flex;
    flex-direction: column;
    align-items: center;
    margin-bottom: 12px;
  }
  .timeline-bullet::after {
    content: "";
    display: block;
    width: 12px;
    height: 12px;
    border-radius: 12px;
    background: white;
  }
  @media (min-width: 1400px) {
    .timeline-entry-gen {
      right: calc(50% + 72px / 2);
    }
    .timeline-entry-ai {
      left: calc(50% + 72px / 2);
    }
    .timeline-entry-gen + .timeline-entry-ai,
    .timeline-entry-ai + .timeline-entry-gen {
      margin-top: -144px;
    }
    .timeline-bullet {
      position: absolute;
      width: 72px;
    }
    .timeline-entry-gen .timeline-bullet {
      left: 100%;
    }
    .timeline-entry-ai .timeline-bullet {
      right: 100%;
    }
  }
</style>
