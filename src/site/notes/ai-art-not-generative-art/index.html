<html lang="en">
  <page-title title="AI art is not generative art" />
  <blog-page path-group="/notes/">
    <content-header slot="precontent" title="AI art is not generative art" />
    <blog-post-info date="25 Mar 2024" hidden />
    <!-- textlint-disable -->
    <tag-row>
      <tag>essay</tag>
    </tag-row>
    <!-- textlint-enable -->
    <!-- prettier-ignore -->
    <markdown>
      **AI art is not _generative art_** (clickbait title). While the technical definition says that one is a subset of the other, I think it’s useful to distinguish between these two categories.

      **Why I’m writing this in the first place &mdash;** Starting 2022, the term “generative art” had been progressively becoming synonymous with art produced by AI text-to-image systems. As a consumer and producer of (traditional) generative art, it was becoming a bit annoying to browse generative art content on the internet. Whether through tags like `#generativeart` or communities like `r/generative`, spaces are being flooded with AI-generated images which I and many others are not interested in. End rant.

      <box-note>In 2024, things are a bit different. AI art is now commonly referred to as ‘AI art’. I shouldn’t have procrastinated writing this post for so long.</box-note>

      There are also cases where generative artists are pressured to relabel their art, so as to not be mistaken for being AI (and avoid things associated with it). It’s an unfortunate niche pressured to be nichey-er.

      It’s kinda like animals vs humans. While technically & scientifically, humans are (a subset of) animals; in daily life “animals” usually mean non-human animals, as in “animal lover” and “animal rights”. I digress.
      
      ## Section overview

      This article looks at the similarities and differences between (traditional) generative art and text-to-image AI art in <span style="display:inline-block;transform:rotate(-3deg)">different</span> <span style="display:inline-block;transform:rotate(27deg)">angles</span>. Skip to different sections if you want.

      1. [History](#history)
      2. [Craft](#the-craft)
      3. [Process](#the-process)

      ## History

      Tracing the history of each practice may offer insights and nuance. Don’t worry, there are pictures! ~~And interactive things!~~ <small>(too lazy to implement interactive things for now)</small>
      
      <span style="opacity: 0.7">This is not a comprehensive history of either field. Btw, this timeline layout is better viewed on a large screen.</span>

      <div class="timeline">
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">1940s</div>
          <card class="timeline-card">
            The first <strong>artificial neural networks</strong> were proposed; abstract machines modeled after biological neurons (brain cells).
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <blog-media :src="url('neurons.png')" alt="Diagrams of a human neuron and an artificial neuron" />
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">1950s</div>
          <card class="timeline-card">
            <h3>The Perceptron</h3>
            <p><text-link href="https://en.wikipedia.org/wiki/Frank_Rosenblatt">Frank Rosenblatt</text-link> built a relatively simple neural network that can be trained, called the <em>perceptron</em>.</p>
            <p>The perceptron was designed for image recognition. The perceptron looks at some input (an image) and decides from a set of pre-learned classes of images, which kind of image it is.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">1960s</div>
          <card class="timeline-card">
            <h3>Conceptual art</h3>
            <p>Artist <text-link href="https://en.wikipedia.org/wiki/Sol_LeWitt#Wall_drawings">Sol LeWitt</text-link> started doing something called wall drawings, which are sets of instructions that produce abstract drawings. These can be thought of as precursors to generative art.</p>
            <p>Example Wall Drawing:</p>
            <blockquote>“<strong>Wall Drawing #797.</strong> <i>The first drafter has a black marker and makes an irregular horizontal line near the top of the wall. Then the second drafter tries to copy it (without touching it) using a red marker. The third drafter does the same, using a yellow marker. The fourth drafter does the same using a blue marker. Then the second drafter followed by the third and fourth copies the last line drawn until the bottom of the wall is reached.</i>”</blockquote>
            <!-- todo: popout interactive -->
            <blog-media :src="url('lewitt.jpg')" alt="Picture of Wall Drawing #797" caption="Product of Wall Drawing #797, executed from instructions written by LeWitt." />
            <p><i>"The idea becomes a machine that makes the art."</i> (Paragraphs on Conceptual Art, 1967) It’s not quite ‘generative art’ but it’s close. Besides, LeWitt called it something else: <strong>‘conceptual art’</strong>.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">1960s</div>
          <card class="timeline-card">
            <h3>Code art</h3>
            <p><text-link href="https://en.wikipedia.org/wiki/Vera_Moln%C3%A1r">Vera Molnár</text-link> brought us closer to modern generative art by actually using computers and writing code to generate artworks.</p>
            <!-- todo: popout interactive -->
            <blog-media :src="url('molnar.jpg')" alt="Picture of art of Vera Molnár" caption="Vera Molnár" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">1970s</div>
          <card class="timeline-card">
            <h3>AI winter ⛄</h3>
            <p>The limitations of relatively primitive AI and weak computing power back then resulted in massive disappointment about AI. Budgets were cut. R&D slowed down. Hype was lost.</p>          
            <p>The Perceptron did not achieve self-awareness as promised.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">1990s</div>
          <card class="timeline-card">
            <p>Artists began meeting in generative art conferences and the artistic community started converging on a shared definition of generative art.</p>
            <blockquote><strong>Generative art &mdash;</strong> work that has been produced by the execution, usually by a computer system, of a set of rules or procedures determined by the artist.</blockquote>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2010s</div>
          <card class="timeline-card">
            <h3>Deep learning</h3>
            <p>The intersection of advancements in computing power, improved machine learning algorithms, and huge ever-growing datasets of digital things resulted in bigger and better neural networks. The great potential of AI was reignited. It’s the start of the <strong>deep learning revolution</strong>.</p>
            <p>Image recognition, picture captioning, automated language translation, text-to-speech, speech-to-text, etc. got seriously buffed.</p>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <blog-media :src="url('deepdream.jpg')" alt="Picture of DeepDream output" caption="Google’s DeepDream exploits image recognition feeding into digital pareidolia. It can be considered early AI art, but it’s quite different from modern AI art." />
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <card class="timeline-card">
            <h3>Generative networks</h3>
            <p>Due to deep learning, we had advancements in generative networks, which are networks that can generate new data on their own instead of simply being a complex input-output mapping.</p>
            <p>This appears to be the start of the <strong>image synthesis</strong> wave.</p>
            <p>
              <responsive-img class="thisperson" alt="Portrait of a person" :src="url('thisperson.jpg')" spec="100" /> Here is a fake person generated by a generative adversarial network (GAN) trained specifically on portraits. Tap to regenerate a new one from <text-link href="https://www.thispersondoesnotexist.com/">thispersondoesnotexist.com</text-link>.
            </p>
            <div style="clear:left"></div>
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2015</div>
          <card class="timeline-card">
            <h3>Text to image</h3>
            <p>The first modern text-to-image model was introduced.</p>
            <p>It was called <strong>alignDRAW</strong>.</p>
            <p>It can generate images from <em>natural language descriptions</em>, making these machines massively accessible to the general public. Anyone could potentially create any image!</p>
            <blog-media :src="url('aligndraw.jpg')" alt="8 blurry images of a white blob on a green background" caption="alignDRAW’s output for “A toilet seat sits open in
            the grass field.”" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2021</div>
          <card class="timeline-card">
            <p><strong><text-link href="https://en.wikipedia.org/wiki/DALL-E">DALL·E</text-link></strong> was revealed by OpenAI. Another text-to-image model, and it became famous. (Or, rather it was made famous by “DALL-E mini” which was <em>viral</em>.)</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('dalle.png')" alt="Image of a toilet seat in a field" caption="DALL·E’s output for “A toilet seat sits open in the grass field.”" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">2022</div>
          <card class="timeline-card">
            <p>Meanwhile, 2022 saw a burst of NFTs, most of which have been associated with generative art.</p>
            <p>Honestly, some of them are on the borderline shallow end of generative art, Mad Libs-style images generated from shufflings of pre-drawn hairstyles, sunglasses, and clothes. Automated dress-up. They are more akin to the <text-link href="https://en.wikipedia.org/wiki/Musikalisches_W%C3%BCrfelspiel">musical dice game</text-link>.</p>
            <blog-media :src="url('apes.png')" alt="Images resembling the Bored Apes collection of images" caption="Typical images associated with NFTs" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2022</div>
          <card class="timeline-card">
            <p>Text-to-image models were approaching the quality of real images. Generated artworks were approaching the quality of human art.</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('house.png')" alt="Image of a painting of a house" caption="AI-generated painting" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-gen">
          <div class="timeline-bullet">2020s</div>
          <card class="timeline-card">
            <p>Today, we see different techniques and tools to make generative art, from straight up canvas coding, to frameworks like <text-link href="https://p5js.org/">p5.js</text-link>, to full-blown authoring software like <text-link href="https://derivative.ca/">TouchDesigner</text-link> and <text-link href="https://www.sidefx.com/">Houdini</text-link>.</p>
            <!-- todo: interactive (just cycle through prerendereds) -->
            <blog-media :src="url('qql.jpg')" alt="Abstract art composed of many non-overlapping small circles" caption="An output of the QQL algorithm which uses the p5.js library" />
          </card>
        </div>
        <div class="timeline-entry timeline-entry-ai">
          <div class="timeline-bullet">2020s</div>
          <card class="timeline-card">
            <p>Tools to make AI art and images have been heavily commercialised, with online image generation services provided by OpenAI/Microsoft, Google, and Midjourney. There are also local models for advanced users and tinkerers.</p>
            <blog-media :src="url('midjournee.png')" alt="Screenshot of an online image generator" caption="Microsoft’s image creator which at the time used the DALL·E 3 model" />
          </card>
        </div>
      </div>

      So. AI art is a relatively new movement borne out of general image synthesizers. This was made possible since visual artworks are images too. Meanwhile, there have been decades of development and refinement in (traditional) generative art, techniques, and algorithms.
      
      The terminology may overlap (generative networks ~ generative art), but these are just labels. You may call them whatever you want, but they’re still <strong>separate art movements that cannot be historically reconciled</strong>.

      <box-note>By the way, I don’t care if you want to call them ‘art’ or not. That’s not the point of this post. If it bothers you, please imagine that all instances of the word ‘art’ were replaced with ‘image’. Same for the word ‘artist’.</box-note>

      ## The craft

      OK so, whatever sure, history is in the past. Why don’t we look at it in terms of what artists are doing today. What do they do? What do they practise to improve?

      ### Unique skills

      Both practices involve some skills that are not in common with the other. They each have their own defining skills.

      <div class="horizontal-scroll">
        <table class="venn-table">
          <tr>
            <th>Generative artists</th>
            <th>AI artists</th>
          </tr>
          <tr>
            <td class="venn venn-gen">
              programming<br>
              math / geometry / trigonometry<br>
            </td>
            <td class="venn venn-ai">
              prompting<br>
              curation / training<br>
              data science<br>
            </td>
          </tr>
        </table>
      </div>
      <style>
        .venn-table {
          margin: auto;
          padding: 10% 0;
          width: 420px;
          table-layout: fixed;
          text-align: center;
        }
        .venn-table th {
          padding-bottom: 24px;
        }
        .venn {
          position: relative;
        }
        .venn::before {
          content: "";
          position: absolute;
          inset: -20% -10%;
          border-radius: 50%;
          mix-blend-mode: color-dodge;
          z-index: -1;
        }
        .venn-ai::before {
          right: 0;
          background-color: var(--ai-clr-dark);
        }
        .venn-gen::before {
          left: 0;
          background-color: var(--gen-clr-dark);
        }
        .venn-intersection {
          width: 0;
        }
        .venn-intersection-content {
          width: fit-content;
          transform: translate(-50%);
        }
      </style>

      **Generative art** involves programming and uses math (usually geometry or trigonometry) to create graphics. A good undertanding of functions and their domains and ranges and how they compose together is essential, especially when utilising random number generators.
      
      <blog-media :src="url('math.png')" caption="Typical generative art math" />

      Beyond these core skills, there are a lot of areas generative artists could expand into, like graph theory, simulations, fractals, image processing, and other algorithms.

      <blog-media :src="url('pathways.png')"><span slot="caption">
        <text-link href="https://www.fxhash.xyz/generative/slug/scattered-pathways" target="_blank">Scattered Pathways</text-link>  by Nate Nolting.<br>Generative art using a graph pathfinding algorithm
      </span></blog-media>

      **AI art**, on the other hand, is heavy on prompt engineering. It could be as simple as writing English descriptions, or as precise as inputting parameterised labels if the tool allows for it.
      
      <card>
        <b><u>Prompt:</u></b> Dog, (Artist Name, Artist Name), Masterpiece, Studio Quality, 6k, glowing, axe, mecha, science_fiction, solo, weapon, jungle, green_background, nature, outdoors, solo, tree, weapon, mask, dynamic lighting, detailed shading, digital texture painting
        <br><b><u>Negative prompt:</u></b> un-detailed skin, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, ugly eyes, (out of frame:1.3), worst quality, low quality, jpeg artifacts, cgi, sketch, cartoon, drawing, (out of frame:1.1)
        <br><b><u>Parameters:</u></b> Steps: 50, Sampler: Euler a, CFG scale: 7.0, Seed: 1579799523, Face restoration, Size: 512x512
      </card>
      <span class="caption">Example prompt with advanced parameters (e.g. for StableDiffusion)</span>

      Beyond writing prompts, there are several tools that allow more control like influencing certain compositional elements. AI artists could also train or fine-tune models by curating image-label datasets as extra training data.

      <blog-media :src="url('control.png')"><span slot="caption">
        Images generated with <text-link href="https://github.com/lllyasviel/ControlNet" target="_blank">ControlNet</text-link>, controlling the general shape of the subject.
      </span></blog-media>

      There seems to be little to no transferable skills between these practices. Sure, you can program some scripts to automate parts of an AI art workflow, or add an AI filter step to an otherwise procedurally-generated image. But there is no inherent overlap.

      **At the highest level, it is the difference between computer science vs data science. At the lowest, it is the difference between coding and writing English.**
      
      That’s why you can’t just ask an AI artist to please create an interactive audio-reactive visualisation for your music video, or <text-link href="https://www.cityartsydney.com.au/artwork/high-water/">a public art installation that reacts to the weather</text-link>. Likewise, you can’t expect a generative artist to easily generate photorealistic art in seconds.

      ### Skills in common

      One big thing that’s common between these practices is the need to curate. Since there is an element of chaos and randomness in both processes, a curation step is almost always required before finishing a work. Curation requires artistic vision, which could be considered a skill in itself.
      
      <div class="horizontal-scroll">
        <table class="venn-table" aria-label="Venn-diagram showing curation & artistic vision in the intersection between Generative artists and AI artists">
          <tr>
            <td class="venn venn-gen" style="padding-inline-end: 10%">
              <b>Generative<br>artists</b>
            </td>
            <td class="venn-intersection">
              <div class="venn-intersection-content">
                curation<br>
                artistic vision
              </div>
            </td>
            <td class="venn venn-ai" style="padding-inline-start: 10%">
              <b>AI<br>artists</b>
            </td>
          </tr>
        </table>
      </div>

      **What’s curation?** As one finishes a piece, they usually generate multiple outputs by running the process with different seeds or starting parameters. These produce different variations, from which the best one(s) are selected for publishing, discarding the rest. That’s curation.
      
      Alternatively, one might refine and iterate their prompt or program until the outputs satisfy a certain artistic vision.
      
      <blog-media :src="url('uncurated.png')" caption="Uncurated set of outputs from a generative art algorithm" />

      <blog-media :src="url('ai-outputs.png')" caption="AI image generators usually generate multiple outputs at a time for you to curate." />

      It could be argued that having artistic vision and doing iterations are pretty common to all arts, and so those alone don’t make generative art and AI art any more similar to each other than any other art.

      Overall, the significant differences in skillsets mean that **generative artists and AI artists are not interchangeable**, and the same should go for their respective arts.

      ## The process

      Finally, let’s attack the subject from the POV of processes and systems.

      Setting aside the question of whether Art is Product or Process, let us indulge in these animations of art in the process of being products.

      <div
        class="horizontal-scroll"
        style="
          display: grid;
          grid-template-columns: repeat(2, minmax(min(80vw, 320px), min-content));
          gap: 18px"
      >
        <blog-media
          class="no-margin"
          :src="url('diffusion.mp4')"
          caption="AI art being formed via denoising" />
        <blog-media
          class="no-margin"
          :src="url('flowers.mp4')"
          caption="Generative art being formed via procedural strokes" />
      </div>

      Most modern AI image generators are based on diffusion models &mdash; they form images via **‘denoising’**. The animation above (left) shows the sequence of steps to progressively denoise a pure noise image into something coherent based on a prompt. The prompt for the above generation specifically was <i>‘cherry blossom branches against a clear blue sky’</i>.

      The denoising process is a black box, an inscrutable network of billions of artificial neurons trained to generate coherent arrays of pixels.

      Generative art algorithms, on the other hand, are relatively more hand-crafted, less magical. A generative art algorithm consists of instructions to explicitly draw every element that will be in the piece. This is apparent in the above animation (right) where each drawn stroke can be seen. <i>This particular animation was from **<text-link href="https://www.fxhash.xyz/generative/slug/the-soul-of-flowers">The Soul of Flowers</text-link>** by Che-Yu Wu.</i>

      There is large contrast in the transparency of these processes. **One is a black box. The other is literally the instructions to create the art.**

      ### System diagrams

      Beyond the processes themselves, art interacts with the context of its creation. And there is a lot to unpack here, especially for AI art. I’ll use diagrams to illustrate the context of the creation process.

      **In the generative art process,** I see 3 components at the minimum: the artist, the program, and the rendered output.
      
      <blog-media :src="url('gen-system.png')" type="bleed" caption="The generative artist writes the program that renders the piece of art" />

      They may use libraries or frameworks as part of the program, but the artist ultimately writes, at a certain level of abstraction, the specific steps or rules which the program would execute.

      The medium is code.
      
      **In AI art,** there are 4 components to the process: the artist, the model, the rendered output, and *the dataset*.

      <blog-media :src="url('ai-system.png')" type="bleed" caption="The AI artist prompts the model trained from the dataset to produce the piece of art" />

      There is an immediate difference. Unlike AI art, **generative art don’t need datasets**.

      And it’s also a controversial thing, *the dataset*. The data used to train a text-to-image model can consist of billions of images, usually scraped from the internet and includes other artworks by other artists.

      If you consider that the model has been influenced by a lot of other images on the web, then the question of how important the AI artist’s influence over the final piece is raised. *Was that chiaroscuro an artistic choice, or an emergent byproduct of the model? Were those bold paint strokes an explicit expression of the artist, or just some typical style chosen by the model?*
      
      In AI art, there is confusion over which elements were expressed by the artist and which by the machine.

      Leaving the contentious topic of datasets aside, there is another point, but not as essential, of **who authored the main program**. Who created the most crucial piece of the system?
      
      Generative art programs are usually created by the artists themselves, while AI art programs are usually created by AI researchers, only to be used as a product by AI artists.
      
      One *makes* the machine that makes the art, the other *uses* a machine to make the art.
      
      Of course, AI artists could train (not fine-tune!) their own models from scratch, if they have a big(!) enough dataset of their own and some machine learning know-how. But I don't think that’s a common occurrence.

      In summary, one is **a direct expression from the artist where the medium is code**, and the other is a **complicated web of datasets including other artworks, machine learning, and just-add-water kind of products**, and I don’t even know what the medium is.
 
      ## Conclusion

      The point is that these are separate _art mediums_. Or _art movements_, if you will. The histories, the crafts, and the processes point to the same conclusion &mdash; they are no more similar than oil painting is to photography, or a film director to an animator.

      So let’s not confuse one with the other. :)

      <box-note>Some aspects of the post have probably been outdated by the time I publish this post. I’ll still include them in the post because why not.</box-note>

      P.S. a similar thing: <text-link href="https://cryptoisnotcryptocurrency.com">cryptoisnotcryptocurrency.com</text-link>, <text-link href="https://en.wikipedia.org/wiki/Crypto_naming_controversy">Wikipedia article</text-link>.

      Now, I should go back to regular programming for this blog.
    </markdown>
  </blog-page>
</html>

<style>
  :root {
    --ai-clr-dark: #5a2a87;
    --gen-clr-dark: #325300;
  }
  .thisperson {
    float: left;
    shape-outside: circle();
    margin-right: 18px;
    width: 100px;
    height: 100px;
    border-radius: 50%;
  }

  .timeline {
    background: linear-gradient(
      to right,
      transparent calc(50% - 0.5px),
      var(--card-clr) calc(50% - 0.5px),
      var(--card-clr) calc(50% + 0.5px),
      transparent calc(50% + 0.5px)
    );
  }

  .timeline-entry {
    position: relative;
    margin: 12px 0;
  }
  .timeline-card > :first-child {
    margin-top: 0;
  }
  .timeline-card > :last-child {
    margin-bottom: 0;
  }
  .timeline-card h3 {
    font-size: 18px;
    font-family: var(--display-font);
    font-style: italic;
    font-weight: bold;
    text-align: center;
  }
  .timeline-entry-gen .timeline-card {
    border-color: var(--gen-clr-dark);
  }
  .timeline-entry-ai .timeline-card {
    border-color: var(--ai-clr-dark);
  }

  .timeline-bullet {
    display: flex;
    flex-direction: column;
    align-items: center;
    margin-bottom: 12px;
  }
  .timeline-bullet::after {
    content: "";
    display: block;
    width: 12px;
    height: 12px;
    border-radius: 12px;
    background: white;
  }

  @media (min-width: 1400px) {
    .timeline-entry-gen {
      right: calc(50% + 72px / 2);
    }
    .timeline-entry-ai {
      left: calc(50% + 72px / 2);
    }
    .timeline-entry-gen + .timeline-entry-ai,
    .timeline-entry-ai + .timeline-entry-gen {
      margin-top: -72px;
    }
    .timeline-bullet {
      position: absolute;
      width: 72px;
    }
    .timeline-entry-gen .timeline-bullet {
      left: 100%;
    }
    .timeline-entry-ai .timeline-bullet {
      right: 100%;
    }
  }

  .no-margin {
    margin: 0;
  }
</style>

<script client async defer>
  (() => {
    document.querySelector(".thisperson").addEventListener("click", (event) => {
      const { currentTarget } = event;
      currentTarget.src = "./plant.gif";
      currentTarget.addEventListener(
        "load",
        () => (currentTarget.src = "https://www.thispersondoesnotexist.com"),
        { once: true }
      );
    });
  })();
</script>
